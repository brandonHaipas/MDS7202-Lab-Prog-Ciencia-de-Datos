{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPTffTLug7i"
      },
      "source": [
        "# **Laboratorio 11: Pienso, luego predigo 💡**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programación Científica para Ciencia de Datos - Otoño 2025</strong></center>\n",
        "\n",
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Stefano Schiappacasse, Sebastián Tinoco\n",
        "- Auxiliares: Melanie Peña, Valentina Rojas\n",
        "- Ayudantes: Angelo Muñoz, Valentina Zúñiga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy6ikgVYzghB"
      },
      "source": [
        "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no serán revisados**\n",
        "\n",
        "- Nombre de alumno 1: Felipe Hernández M.\n",
        "- Nombre de alumno 2: Brandon Peña H."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMJ-owchzjFf"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Enlace](https://github.com/brandonHaipas/MDS7202-Lab-Prog-Ciencia-de-Datos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUuwsXrKzmkK"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Reinforcement Learning\n",
        "- Large Language Models\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 6 días de plazo con descuento de 1 punto por día. Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia será debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no estén en u-cursos no serán revisados. Recuerden que el repositorio también tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Resolución de problemas secuenciales usando Reinforcement Learning\n",
        "- Habilitar un Chatbot para entregar respuestas útiles usando Large Language Models.\n",
        "\n",
        "El laboratorio deberá ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al máximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante más eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      },
      "source": [
        "## **1. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta sección van a usar métodos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOcejYb6uzOO",
        "outputId": "fdcec8b0-1c49-4de7-d947-9e484dffda50"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq \"gymnasium[box2d]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBPet_Mq8dX9"
      },
      "source": [
        "### **1.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "La idea de esta subsección es que puedan implementar métodos de RL y así generar una estrategia para jugar el clásico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de código transforma las observaciones del ambiente a `np.array`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      },
      "source": [
        "#### **1.1.1 Descripción de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripción sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5i1Wt1p770x"
      },
      "source": [
        "El ambiente de `blackjack` contiene la implementación del juego de Blackjack como un problema de RL. El objetivo del juego es ganarle al _dealer_ consiguiendo cartas cuyo puntaje sume un valor más cercano a 21 (sin superar el 21) que las cartas del _dealer_.\n",
        "\n",
        "El puntaje de cada carta se describe a continuación:\n",
        "- Los _ases_ pueden contar como 11 o 1.\n",
        "- Las cartas J, Q, K tienen un valor de 10.\n",
        "- Las cartas numéricas (2 a 10) tienen un valor equivalente a su número.\n",
        "\n",
        "El juego comienza con el _dealer_ sacando dos cartas: una visible y la otra boca abajo.\n",
        "\n",
        "En cada paso del juego, el jugador puede solicitar _(hit)_ una nueva carta hasta que decida quedarse _(stick)_ con las que posee actualmente. Si al solicitar una nueva carta el jugador supera el valor 21, pierde automáticamente.\n",
        "\n",
        "Una vez el jugador decide quedarse, el _dealer_ revela su carta boca abajo y saca nuevas cartas hasta que la suma de sus puntos sea 17 o mayor, perdiendo si llega a superar el valor 21.\n",
        "\n",
        "La formulación del problema como un _Markov Decision Process_ consiste de los siguientes componentes:\n",
        "- Estados: Cada observación consiste de una 3-tupla $(p, d, a)$, donde $p$ corresponde a la suma de puntos actual del jugador, $d$ el puntaje de la carta visible del _dealer_ (un valor de 1 a 10, donde 1 es un _as_) y $a$ un valor 1 o 0 indicando si el jugador posee o no una carta _as_, respectivamente. Cada uno de estos valores es un número entero.\n",
        "- Acciones: El espacio de acción es de dimensión 1, cuyos posibles valores son:\n",
        "    - 0: Quedarse (stick)\n",
        "    - 1: Solicitar una nueva carta (hit)\n",
        "- Recompensas:\n",
        "    - Ganar el juego: +1 o +1.5 si es un _natural blackjack_ (ganar por comenzar con un _as_ y un 10, el uso del puntaje adicional para este caso es opcional y requiere el uso del argumento `natural=True`)\n",
        "    - Perder el juego: -1\n",
        "    - Empatar el juego: 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcX6bRC9agQ"
      },
      "source": [
        "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulación 5000 veces y reporte el promedio y desviación de las recompensas. ¿Cómo calificaría el performance de esta política? ¿Cómo podría interpretar las recompensas obtenidas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p2PrLLR9yju",
        "outputId": "00c63650-dd2f-4890-cc5f-ec209b07cd78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recompensa promedio: -0.3866\n",
            "Desviación estándar de recompensas: 0.8999669105028251\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "n_simulations = 5000\n",
        "action_space = [0, 1]\n",
        "rewards = []\n",
        "\n",
        "for episode in range(n_simulations):\n",
        "    env.reset(seed=random.randint(1, 10000))\n",
        "    end = False\n",
        "\n",
        "    while not end:\n",
        "        action = random.choice(action_space)\n",
        "        state, reward, done, truncated, info = env.step(action)\n",
        "        end = done | truncated\n",
        "    rewards.append(reward)\n",
        "\n",
        "print('Recompensa promedio:', np.mean(rewards))\n",
        "print('Desviación estándar de recompensas:', np.std(rewards))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance de esta política aleatoria no es buena, en promedio el agente tiene una recompensa negativa de -0.3866, es decir, pierde 2/3 de las veces que no empata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEO_dY4x_SJu"
      },
      "source": [
        "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "m9JsFA1wGmnH",
        "outputId": "c775b65d-b70c-494a-85ca-f6b0a9088557"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d91e1b286d4427fb5c21f96818a371b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.dqn.dqn.DQN at 0x7fe38a7d7cd0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from stable_baselines3 import DQN\n",
        "\n",
        "# init agent\n",
        "model = DQN(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# train the agent and display a progress bar\n",
        "model.learn(total_timesteps=int(2e5), progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-bpdb8wZID1"
      },
      "source": [
        "#### **1.1.4 Evaluación de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. ¿Cómo es el performance de su agente? ¿Es mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-d7d8GFf7F6",
        "outputId": "76b239bc-bc68-4464-f7fc-017f67f54124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recompensa promedio: -0.054\n",
            "Desviación estándar de recompensas: 0.9458773704873165\n"
          ]
        }
      ],
      "source": [
        "n_simulations = 5000\n",
        "rewards = []\n",
        "\n",
        "for episode in range(n_simulations):\n",
        "    end = False\n",
        "    result = None\n",
        "    state, info = env.reset(seed=random.randint(1, 10000))\n",
        "\n",
        "    while not end:\n",
        "        action, _states = model.predict(state, deterministic=True)\n",
        "        action = action.item()\n",
        "        state, reward, done, truncated, info = env.step(action)\n",
        "        end = done | truncated\n",
        "    rewards.append(reward)\n",
        "\n",
        "print('Recompensa promedio:', np.mean(rewards))\n",
        "print('Desviación estándar de recompensas:', np.std(rewards))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOcLZzp3r_nT"
      },
      "source": [
        "La recompensa promedio es mayor y más cercana a 0 y hay más dispersión en estas. Luego, se observa que el agente está actuando con más racionalidad, y tiene mejor performance que el azar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-EsAaPAYEm"
      },
      "source": [
        "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "Genere una función que reciba un estado y retorne la accion del agente. Luego, use esta función para entregar la acción escogida frente a los siguientes escenarios:\n",
        "\n",
        "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "¿Son coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: ¿A que clase de python pertenecen los estados? Pruebe a usar el método `.reset` para saberlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYPy2kxHqZG9",
        "outputId": "250c3dea-a66a-49a4-8c8a-462fa524d628"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([21,  2,  1])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state, info = env.reset()\n",
        "state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P_zcektqxEI"
      },
      "source": [
        "Los estados son de clase `np.array`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh8XlGyzwtRp",
        "outputId": "7517ff75-74ea-4e3d-f72d-5b79d5f62f9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estado: Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
            "Acción: Hit\n",
            "Estado: Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
            "Acción: Stick\n"
          ]
        }
      ],
      "source": [
        "def get_action(state):\n",
        "    action, _states = model.predict(state, deterministic=True)\n",
        "    action = action.item()\n",
        "\n",
        "    if action == 1:\n",
        "        return 'Hit'\n",
        "    else:\n",
        "        return 'Stick'\n",
        "\n",
        "# Definición de estados\n",
        "s1 = np.array([6, 7, 0])\n",
        "s2 = np.array([19, 3, 1])\n",
        "\n",
        "print(\"Estado: Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\\nAcción:\", get_action(s1))\n",
        "print(\"Estado: Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\\nAcción:\", get_action(s2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT-jE172rs7N"
      },
      "source": [
        "Las acciones tienen sentido. En el primer estado, el agente tiene una suma de 6 y sin as, está lejos de 21 y es mejor realizar un \"hit\" para pedir otra carta. En el segundo caso, tiene una suma de 19 y un as, está muy cerca de 21. No tiene sentido pedir otra carta, por lo que decide un \"stick\" para quedarse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqCTqqroh03"
      },
      "source": [
        "### **1.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la sección 2.1, en esta sección usted se encargará de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
        "\n",
        "Comencemos preparando el ambiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nvQUyuZ_FtZ4"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\", continuous = True) # notar el parámetro continuous = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBU4lGX3wpN6"
      },
      "source": [
        "Noten que se especifica el parámetro `continuous = True`. ¿Que implicancias tiene esto sobre el ambiente?\n",
        "\n",
        "Además, se le facilita la función `export_gif` para el ejercicio 2.2.4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bRiWpSo9yfr9"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  función que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk5VJVppXh3N"
      },
      "source": [
        "#### **1.2.1 Descripción de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripción sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulación en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. ¿Como se distinguen las acciones de este ambiente en comparación a `Blackjack`?\n",
        "\n",
        "Nota: recuerde que se especificó el parámetro `continuous = True`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb-u9LUE8O9a"
      },
      "source": [
        "El ambiente `Lunar Lander` contiene un problema de optimización de la trayectoria de un cohete en 2D, con el objetivo de aterrizar en una plataforma en la posición (0,0), planteado como un problema de RL.\n",
        "\n",
        "En cada episodio, el cohete debe decidir una secuencia de movimientos de motor y propulsores (encenderlos o apagarlos) para aterrizar correctamente. El episodio termina si:\n",
        "\n",
        "- El cohete choca (su cuerpo entra en contacto con la superficie).\n",
        "- El cohete sale de la vista (coordenada $x$ con magnitud mayor a 1).\n",
        "- El cohete está en reposo.\n",
        "\n",
        "Su formulación en MDP consiste de los siguientes componentes (tomando en consideración el uso del parámetro `continuous=True`:\n",
        "\n",
        "- Estados: Cada observación corresponde a un vector de 8 dimensiones, con las coordenadas de la posición del cohete ($x$ e $y$ ambos con valores entre -2.5 y +2.5), sus velocidades lineales en $x$ e $y$ (ambas de -10 a +10), su ángulo de inclinación (de $-2\\pi$ a $+2\\pi$), su velocidad angular (de -10 a +10) y dos valores `booleans` que representan si cada \"pata\" del cohete están en contacto con la superficie o no.\n",
        "\n",
        "- Acciones: A diferencia del ambiente de `blackjack`, el espacio de acción es continuo, conformado por dos coordenadas (`main`, `lateral`) que pueden tomar valores de -1 a +1. La primera coordenada `main` indica la aceleración del motor principal del cohete, estándo completamente apagado cuando `main < 0` y escala de forma lineal entre 50% y 100% cuando `0 <= main <= 1`. De manera similar, la coordenada `lateral` indica la aceleración de los propulsores laterales, donde estarán ambos apagados si `-0.5 < lateral < 0.5` y escalará la propulsión linealmente entre 50% y 100% si `-1 <= lateral <= -0.5` (o `0.5 <= lateral <= 1`) para el propulsor izquierdo (o derecho, respectivamente).\n",
        "\n",
        "- Recompensas: A diferencia del ambiente de `blackjack` (donde la recompensa se obtiene sólo al terminar el juego) hay una recompensa después de cada paso, obteniendose una recompensa total del espisodio como la suma de las obtenidas en cada paso de este.\n",
        "\n",
        "    Para cada paso, la recompensa:\n",
        "\n",
        "    - Aumenta/disminuye según lo cerca/lejos se encuentre el cohete de la plataforma de aterrizaje.\n",
        "    - Aumenta/disminuye según lo lento/rápido se mueva el cohete.\n",
        "    - Disminuye mientras más inclinado esté el cohete.\n",
        "    - Aumenta en 10 puntos por cada \"pata\" en contacto con la superficie.\n",
        "    - Disminuye en 0.03 puntos por cada \"cuadro\" de la trayectoria donde un propulsor esté encendido.\n",
        "    - Disminuye en 0.3 puntos por cada \"cuadro\" de la trayectoria donde el motor principal esté encendido.\n",
        "\n",
        "    Un episodio recibe una recompensa adicional en los siguientes casos:\n",
        "\n",
        "    - Aumenta 100 puntos si aterriza de forma segura.\n",
        "    - Disminuye 100 puntos si choca.\n",
        "\n",
        "    Finalmente, un episodio se considera una solución válida si logra al menos 100 puntos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YChodtNQwzG2"
      },
      "source": [
        "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulación 10 veces y reporte el promedio y desviación de las recompensas. ¿Cómo calificaría el performance de esta política?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bwc3A0GX7a8",
        "outputId": "f6dbc949-9ebf-47cc-8c10-6446ef622de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recompensa promedio: -100.0\n",
            "Desviación estándar de recompensas: 0.0\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "n_simulations = 10\n",
        "rewards = []\n",
        "\n",
        "for episode in range(n_simulations):\n",
        "    env.reset(seed=random.randint(1, 10000))\n",
        "    end = False\n",
        "\n",
        "    while not end:\n",
        "        main = random.uniform(-1, 1)\n",
        "        lateral = random.uniform(-1, 1)\n",
        "        state, reward, done, truncated, info = env.step([main, lateral])\n",
        "        end = done | truncated\n",
        "    rewards.append(reward)\n",
        "\n",
        "print('Recompensa promedio:', np.mean(rewards))\n",
        "print('Desviación estándar de recompensas:', np.std(rewards))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMM1JixLuePW"
      },
      "source": [
        "La performance de esta política es mala, en promedio la recompensa es de -100, lo que indica que el cohete siempre choca."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQrZVQflX_5f"
      },
      "source": [
        "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "5a115967f34d4dcebbf328cc16ecb845",
            "0678c1f060f54ad289eeb8cc079a4739"
          ]
        },
        "id": "y_6Ia9uoF7Hs",
        "outputId": "f5def390-a066-4a3c-d92a-57e6867a314e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "223c260c3cd645adb819881228809b19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7fe38db52610>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "# init agent\n",
        "model = PPO(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# train the agent and display a progress bar\n",
        "model.learn(total_timesteps=10000, progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z-oIUSrlAsY"
      },
      "source": [
        "#### **1.2.4 Evaluación de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. ¿Cómo es el performance de su agente? ¿Es mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ophyU3KrWrwl",
        "outputId": "b70ccaf4-2ec5-472c-b199-d1d0577615db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recompensa promedio: -100.0\n",
            "Desviación estándar de recompensas: 0.0\n"
          ]
        }
      ],
      "source": [
        "n_simulations = 10\n",
        "rewards = []\n",
        "\n",
        "for episode in range(n_simulations):\n",
        "    end = False\n",
        "    result = None\n",
        "    state, info = env.reset(seed=random.randint(1, 10000))\n",
        "\n",
        "    while not end:\n",
        "        action, _states = model.predict(state, deterministic=True)\n",
        "        state, reward, done, truncated, info = env.step(action)\n",
        "        end = done | truncated\n",
        "    rewards.append(reward)\n",
        "\n",
        "print('Recompensa promedio:', np.mean(rewards))\n",
        "print('Desviación estándar de recompensas:', np.std(rewards))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance sigue siendo igual de mala que el caso baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      },
      "source": [
        "#### **1.2.5 Optimización de modelo (0.2 puntos)**\n",
        "\n",
        "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente parámetros como:\n",
        "- `total_timesteps`\n",
        "- `learning_rate`\n",
        "- `batch_size`\n",
        "\n",
        "Una vez optimizado el modelo, use la función `export_gif` para estudiar el comportamiento de su agente en la resolución del ambiente y comente sobre sus resultados.\n",
        "\n",
        "Adjunte el gif generado en su entrega (mejor aún si además adjuntan el gif en el markdown)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "be65422cf0be4c90bab935bc012c609d",
            "cabdbad743c54b05bdbe6e0606611f8f"
          ]
        },
        "id": "aItYF6sr6F_6",
        "outputId": "6d9c3744-496b-4251-c318-ab98056ef31a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4ead3e986964cfeb28e265bb532c6eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7fe2af1f3250>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2 = PPO(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# train the agent and display a progress bar\n",
        "model2.learn(total_timesteps=200000, progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2A78xHk1zBP",
        "outputId": "9e85198f-2d92-4543-a70d-07ac8cb3f917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recompensa promedio: 80.0\n",
            "Desviación estándar de recompensas: 60.0\n"
          ]
        }
      ],
      "source": [
        "n_simulations = 10\n",
        "rewards = []\n",
        "\n",
        "for episode in range(n_simulations):\n",
        "    end = False\n",
        "    result = None\n",
        "    state, info = env.reset(seed=random.randint(1, 10000))\n",
        "\n",
        "    while not end:\n",
        "        action, _states = model2.predict(state, deterministic=True)\n",
        "        state, reward, done, truncated, info = env.step(action)\n",
        "        end = done | truncated\n",
        "    rewards.append(reward)\n",
        "\n",
        "print('Recompensa promedio:', np.mean(rewards))\n",
        "print('Desviación estándar de recompensas:', np.std(rewards))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xfSltZ92JG3",
        "outputId": "41425d0e-dca9-468a-bdd8-3c7b0365a629"
      },
      "outputs": [],
      "source": [
        "export_gif(model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al entrenar con 200000 timesteps el agente obtiene una recompensa promedio de 80. A continuación se puede visualizar el gif generado, donde se aprecia que el agente aterriza de forma cuidadosa, casi dentro de la plataforma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYgiiowa2K9M"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"agent_performance.gif\"\n",
        "\" width=\"400\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPUY-Ktgf2BO"
      },
      "source": [
        "## **2. Large Language Models (4.0 puntos)**\n",
        "\n",
        "En esta sección se enfocarán en habilitar un Chatbot que nos permita responder preguntas útiles a través de LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ4fPRRihGLe"
      },
      "source": [
        "### **2.0 Configuración Inicial**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Como siempre, cargamos todas nuestras API KEY al entorno:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ud2Xm_k-hFJn"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
        "\n",
        "if \"TAVILY_API_KEY\" not in os.environ:\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj9JvQUsgZZJ"
      },
      "source": [
        "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsección es que habiliten un chatbot que pueda responder preguntas usando información contenida en documentos PDF a través de **Retrieval Augmented Generation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxOQroVnaZ5"
      },
      "source": [
        "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
        "\n",
        "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
        "  - 2 documentos .pdf como mínimo.\n",
        "  - 50 páginas de contenido como mínimo entre todos los documentos.\n",
        "  - Ideas para documentos: Documentos relacionados a temas académicos, laborales o de ocio. Aprovechen este ejercicio para construir algo útil y/o relevante para ustedes!\n",
        "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
        "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
        "  - **Recuerden adjuntar los documentos en su entrega**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D1tIRCi4oJJ",
        "outputId": "d2c7439a-bf97-4ad1-e453-2aaf3c3600d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kzq2TjWCnu15"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "doc_paths = [\"coli_a_00524.pdf\", \"2409.16430v1.pdf\"] # rellenar con los path a sus documentos\n",
        "\n",
        "assert len(doc_paths) >= 2, \"Deben adjuntar un mínimo de 2 documentos\"\n",
        "\n",
        "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
        "assert total_paginas >= 50, f\"Páginas insuficientes: {total_paginas}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r811-P71nizA"
      },
      "source": [
        "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
        "\n",
        "Vectorice los documentos y almacene sus representaciones de manera acorde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vth3TGUUzj-p",
        "outputId": "6875fb48-f8b1-49fc-a916-e07f9d51be47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet langchain-google-genai faiss-cpu langchain_community pypdf wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "n-yXAdCSn4JM"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "def generate_vectorstore(doc_paths=doc_paths, chunk_size=500, chunk_overlap=50):\n",
        "    docs = list()\n",
        "\n",
        "    # Load\n",
        "    for doc in doc_paths:\n",
        "        loader = PyPDFLoader(doc)\n",
        "\n",
        "        docs += loader.load()\n",
        "\n",
        "    # Split\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap) # inicializamos splitter\n",
        "    splits = text_splitter.split_documents(docs) # dividir documentos en chunks\n",
        "\n",
        "    # Embed & Store\n",
        "    embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
        "    vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
        "    return vectorstore\n",
        "\n",
        "base_vectorstore = generate_vectorstore()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAUkP5zrnyBK"
      },
      "source": [
        "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
        "\n",
        "Habilite la solución RAG a través de una *chain* y guárdela en una variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "gPIySdDFn99l"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\", # modelo de lenguaje\n",
        "    temperature=0, # probabilidad de \"respuestas creativas\"\n",
        "    max_tokens=None, # sin tope de tokens\n",
        "    timeout=None, # sin timeout\n",
        "    max_retries=2, # número máximo de intentos\n",
        ")\n",
        "\n",
        "# Función auxiliar para formatear respuesta\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "def generate_rag_chain(vectorstore=base_vectorstore, k=3, search_type=\"similarity\"):\n",
        "    # Retriever chain\n",
        "    retriever = vectorstore.as_retriever(search_type=search_type, # método de búsqueda\n",
        "                                        search_kwargs={\"k\": k}, # n° documentos a recuperar\n",
        "                                        )\n",
        "    retriever_chain = retriever | format_docs # chain\n",
        "\n",
        "    # RAG chain\n",
        "    llm_bias_rag_template = '''\n",
        "    You are an expert assistant specializing in biases in large language models (LLMs).\n",
        "    Your sole role is to answer user questions strictly based on the relevant information provided to you.\n",
        "    Always provide the most comprehensive and precise response possible, using only the supplied context.\n",
        "    Answer only what is asked; NEVER fabricate or infer details beyond the given information.\n",
        "\n",
        "    Relevant information: {context}\n",
        "    Question: {question}\n",
        "    Answer:\n",
        "    '''\n",
        "\n",
        "    rag_prompt = PromptTemplate.from_template(llm_bias_rag_template)\n",
        "\n",
        "    rag_chain = (\n",
        "        {\n",
        "            \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
        "            \"question\": RunnablePassthrough(), # question pasará directo hacia el prompt\n",
        "        }\n",
        "        | rag_prompt # prompt con las variables question y context\n",
        "        | llm # llm recibe el prompt y responde\n",
        "        | StrOutputParser() # recuperamos sólo la respuesta\n",
        "    )\n",
        "\n",
        "    return rag_chain\n",
        "\n",
        "base_rag_chain = generate_rag_chain()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycg5S5i_n-kL"
      },
      "source": [
        "#### **2.1.4 Verificación de respuestas (0.5 puntos)**\n",
        "\n",
        "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su solución para cada una. ¿Su solución RAG entrega las respuestas que esperaba?\n",
        "\n",
        "Ejemplo de tupla:\n",
        "- Pregunta: ¿Quién es el presidente de Chile?\n",
        "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR-efkaY5ll9"
      },
      "source": [
        "Se definen las siguientes tuplas:\n",
        "- Tupla 1:\n",
        "    - Pregunta: What are social biases?\n",
        "    - Respuesta correcta: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
        "- Tupla 2:\n",
        "    - Pregunta: Which word embedding-based metrics exist for measuring bias in LLMs?\n",
        "    - Respuesta correcta: Word Embedding metrics and Sentence Embedding metrics\n",
        "- Tupla 3:\n",
        "    - Pregunta: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
        "    - Respuesta correcta: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDfYt2UC6GUN",
        "outputId": "c16a18cf-5e35-470e-da91-8dc5798be241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Social biases are defined as disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries. Within the LLM system, social bias reflects societal prejudices and stereotypes present in training data.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: The provided information describes what embedding-based metrics are and what they use, but it does not list specific names of embedding-based metrics that exist for measuring bias in LLMs. It mentions \"Word Embedding Metrics\" as a category and states that one relevant method for static word embeddings is presented, but does not name it.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: The types of techniques for bias mitigation in LLMs that intervene in the pre-processing stage are:\n",
            "*   Data Augmentation\n",
            "*   Data Filtering & Reweighting\n",
            "*   Data Generation\n",
            "*   Instruction Tuning\n",
            "\n"
          ]
        }
      ],
      "source": [
        "questions = [\n",
        "    (\"What are social biases?\", \"Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\"),\n",
        "    (\"Which embedding-based metrics exists for measuring bias in LLMs?\", \"Word Embedding metrics and Sentence Embedding metrics\"),\n",
        "    (\"What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\", \"Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\")\n",
        "]\n",
        "\n",
        "def ask_questions(chain=base_rag_chain):\n",
        "    for q in questions:\n",
        "        print(\"Question: \" + q[0] + '\\nExpected Answer: ' + q[1] + '\\nAnswer: ' + chain.invoke(q[0]) + \"\\n\")\n",
        "\n",
        "ask_questions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El RAG entrega una buena respuesta para las preguntas 1 y la 3, pero la tupla 2 es menos precisa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8d5zTMHoUgF"
      },
      "source": [
        "#### **2.1.5 Sensibilidad de Hiperparámetros (0.5 puntos)**\n",
        "\n",
        "Extienda el análisis del punto 2.1.4 analizando cómo cambian las respuestas entregadas cambiando los siguientes hiperparámetros:\n",
        "- `Tamaño del chunk`. (*¿Cómo repercute que los chunks sean mas grandes o chicos?*)\n",
        "- `La cantidad de chunks recuperados`. (*¿Qué pasa si se devuelven muchos/pocos chunks?*)\n",
        "- `El tipo de búsqueda`. (*¿Cómo afecta el tipo de búsqueda a las respuestas de mi RAG?*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDh_QgeXLGHc",
        "outputId": "a1c76835-e33d-4e81-b948-bc6a29216c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Based on the provided information, social bias is described as \"a subjective and\" (the description is incomplete in the provided text). Racial bias is also stated to be a form of social bias.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: The provided information states that \"Bias in the embedding space can have a\" in the context of metrics for assessing bias in LLMs. However, it does not list any specific embedding-based metrics.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: Based on the provided information, there is no mention of bias mitigation techniques that intervene in the pre-processing stage. The text only refers to \"post-processing bias mitigations\" and general \"bias mitigations apply to an LLM\".\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambio de tamaño de chunk\n",
        "vectorstore_small_chunk = generate_vectorstore(chunk_size=50)\n",
        "rag_chain_small_chunk = generate_rag_chain(vectorstore=vectorstore_small_chunk)\n",
        "ask_questions(chain=rag_chain_small_chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Based on the provided information, \"social bias\" is referred to as \"bias\" unless otherwise specified, and its definition is stated to be in \"Definition 7.\" However, \"Definition 7\" is not included in the provided text. Therefore, the specific definition of social bias is not available in the given context.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: Embedding-based metrics for measuring bias in LLMs include Word Embedding Metrics. These metrics typically compute distances in the vector space between neutral words (e.g., professions) and identity-related words (e.g., gender pronouns). While first proposed for static word embeddings, their basic formulation of computing cosine distances between neutral and gendered words has been generalized to contextualized embeddings used in LLMs.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: The types of techniques for bias mitigation in LLMs that intervene in the pre-processing stage are:\n",
            "\n",
            "*   Data Augmentation\n",
            "*   Data Filtering & Reweighting\n",
            "*   Data Generation\n",
            "*   Instruction Tuning\n",
            "*   Projection-based Mitigation\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambio de tamaño de chunk\n",
        "vectorstore_big_chunk = generate_vectorstore(chunk_size=1000)\n",
        "rag_chain_big_chunk = generate_rag_chain(vectorstore=vectorstore_big_chunk)\n",
        "ask_questions(chain=rag_chain_big_chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al utilizar chunks más pequeños, el texto parece ser insuficiente para responder preguntas complejas que antes si podía resolver, como la tupla 3. Por otro lado, al usar chunks más grandes el texto proporcionado es de mayor tamaño, y algunas respuestas son más complejas, como la de la tupla 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Social biases are defined as disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: Based on the provided information, the text defines embedding-based metrics as those that use dense vector representations, typically contextual sentence embeddings, to measure bias. However, it does not list or name any specific embedding-based metrics.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: The types of techniques that exist for Bias Mitigation in LLMs that intervene in the pre-processing stage are:\n",
            "*   Data Augmentation\n",
            "*   Data Filtering & Reweighting\n",
            "*   Data Generation\n",
            "*   Instruction Tuning\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambio de cantidad de chunk recuperados\n",
        "rag_chain_less_chunks = generate_rag_chain(k=1)\n",
        "ask_questions(chain=rag_chain_less_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSPOgSsB7g2A",
        "outputId": "4f20ac62-087a-4a0d-813a-ac38d4d52c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Social bias broadly encompasses disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries. It is a subjective and normative term used to refer to harms such as stereotypes, misrepresentations, derogatory and exclusionary language, and other denigrating behaviors that disproportionately affect already-vulnerable and marginalized communities.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: Based on the provided information, the text describes how embedding-based metrics work (e.g., computing distances in vector space between neutral words and identity-related words, or using cosine similarity to compare words like \"doctor\" to social group terms like \"man\"), but it does not list specific names of embedding-based metrics for measuring bias in LLMs.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: Bias mitigation techniques that intervene in the pre-processing stage include:\n",
            "\n",
            "*   **Data Augmentation** (§ 5.1.1): This involves extending the distribution with new data.\n",
            "*   **Data Filtering & Reweighting** (§ 5.1.2): This technique focuses on removing or reweighting instances.\n",
            "*   **Data Generation** (§ 5.1.3): This involves producing new data that meets certain standards.\n",
            "*   **Instruction Tuning** (§ 5.1.4): This technique involves prepending additional instructions or triggers to a prompt to generate an unbiased output.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambio de cantidad de chunk recuperados\n",
        "rag_chain_more_chunks = generate_rag_chain(k=20)\n",
        "ask_questions(chain=rag_chain_more_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al recuperar pocos chunks (y por ello, menos texto), las respuestas son más dificiles de responder, como en la pregunta 2, donde se indica que el texto es insuficiente. Mientras que muchos chunks de texto aportan más información encontrada, permitiendo construir respuestas más complejas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTCvwIaz8qiT",
        "outputId": "5e82a54a-3837-41d4-9f9a-2d0496ca16ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Social bias refers to disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: Based on the provided information, the text defines embedding-based metrics as those that use dense vector representations, typically contextual sentence embeddings, to measure bias. However, it does not list any specific named embedding-based metrics for measuring bias in LLMs. The \"EMBEDDINGS\" section in Table 6 refers to objective functions for bias *mitigation* by modifying embeddings, not metrics for measuring bias.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: The types of techniques that exist for Bias Mitigation in LLMs that intervene in the pre-processing stage are:\n",
            "*   Data Augmentation\n",
            "*   Data Filtering & Reweighting\n",
            "*   Data Generation\n",
            "*   Instruction Tuning\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambio de tipo de busqueda\n",
        "rag_chain_other_search = generate_rag_chain(search_type=\"mmr\")\n",
        "ask_questions(chain=rag_chain_other_search)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, al cambiar la función de búsqueda la tupla 2 incorpora información más información, pero sin lograr responder correctamente, mientras que la tupla 1 entrega una respuesta casi perfecta y la 3 se mantiene constante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENJiPPM0giX8"
      },
      "source": [
        "### **2.2 Agentes (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la sección anterior, en esta sección se busca habilitar **Agentes** para obtener información a través de tools y así responder la pregunta del usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V47l7Mjfrk0N"
      },
      "source": [
        "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas al motor de búsqueda **Tavily**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "R6SLKwcWr0AG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31006/4138654522.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tavily_search = TavilySearchResults(max_results = 1)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_search = TavilySearchResults(max_results = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SonB1A-9rtRq"
      },
      "source": [
        "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
        "\n",
        "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ehJJpoqsr26-"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
        "wikipedia_query = WikipediaQueryRun(api_wrapper=api_wrapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvUIMdX6r0ne"
      },
      "source": [
        "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
        "\n",
        "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. Asegúrese que su agente responda en español. Por último, guarde el agente en una variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "pD1_n0wrsDI5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/felipe/.pyenv/versions/lab11/lib/python3.11/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: capital de chile\u001b[0m\u001b[33;1m\u001b[1;3mPage: Santiago\n",
            "Summary: Santiago (, US also ; Spanish: [sanˈtjaɣo]), also known as Santiago de Chile\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: La capital de Chile es Santiago.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "La capital de Chile es Santiago.\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "\n",
        "tools = [tavily_search, wikipedia_query]\n",
        "react_prompt = hub.pull(\"hwchase17/react\")\n",
        "agent = create_react_agent(llm, tools, react_prompt) # primero inicializamos el agente ReAct\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # lo transformamos a AgentExecutor para habilitar la ejecución de tools\n",
        "\n",
        "response = agent_executor.invoke({\"input\": \"Hola, cual es la capital de chile?\"})\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El agente responde en español si problemas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKV0JxK3r-XG"
      },
      "source": [
        "#### **2.2.4 Verificación de respuestas (0.3 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente y asegúrese que el agente esté ocupando correctamente las tools disponibles. ¿En qué casos el agente debería ocupar la tool de Tavily? ¿En qué casos debería ocupar la tool de Wikipedia?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El agente debería usar la tool de Tavily cuando la pregunta es sobre poco precisa respecto al tópico, como al consultar \"Cómo puedo cocinar un pollo?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "15NvwR7Z_9TR",
        "outputId": "7deb1143-7431-49f6-8454-1e23568f01af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: cómo cocinar un pollo\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Pollo en salsa. Receta tradicional y casera', 'url': 'https://recetasdecocina.elmundo.es/2024/10/pollo-en-salsa-receta-tradicional-y-casera.html', 'content': 'Hacer pollo en salsa ... 1.- Comenzamos salpimentando los trozos de pollo y dorándolos a fuego fuerte en una cocerlo. Una vez dorados, los', 'score': 0.523494}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: métodos para cocinar pollo\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Cómo cocinar las distintas partes del pollo - Recetas Nestlé', 'url': 'https://www.recetasnestlecam.com/escuela-sabor/recetas/preparaciones-pollo', 'content': 'La mejor pechuga de pollo · A la plancha: este método se suele usar con los filetes, aprovechando que son más delgados. · En brochetas: aprovecha', 'score': 0.6342494}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: formas comunes de cocinar pollo\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Las 71 mejores recetas de pollo - Directo al Paladar', 'url': 'https://www.directoalpaladar.com/recetario/71-mejores-recetas-pollo', 'content': 'Pocos elementos nos han dado en la cocina tantos momentos de gloria como el pollo. No importa el formato, corte o tipo de receta, pues **siempre hay una receta de pollo para cada momento** o tipo de cocina.\\n\\nDa igual que hablemos de pollos asados o de pollo frito. También da igual que hablemos de alitas de pollo, de muslos de pollo o los no menos relevantes contramuslos de pollo. Sea la pieza que sea, el pollo tiene un camino común: ser **bueno, bonito y barato**. [...] Tras una intensa criba, podemos asegurarte que estas son **nuestras mejores recetas de pollo,** que vas a encontrar ordenadas por tipo de preparación —ya sea frito, asado, al horno, a la plancha, guisado, a la parrilla…— y por tipo de corte, para que tengas a mano esta pequeña biblia gastronómica con la que convertir el pollo en un placer irresistible.\\n\\nGuisos de pollo\\n--------------- [...] *   [Pollo al horno con patatas](https://www.directoalpaladar.com/recetas-de-carnes-y-aves/pollo-al-horno-patatas-chorizo-receta-facilisima-para-uno)\\n*   [Pollo asado en olla exprés](https://www.directoalpaladar.com/recetas-de-carnes-y-aves/como-hacer-pollo-asado-olla-expres-receta-rapida-limpia-pollo-encender-horno)\\n*   [Pollo al carbón](https://www.directoalpaladar.com/recetas-de-carnes-y-aves/receta-pollo-al-carbon-marinado-asado-perfecto-para-parrilla-grill)', 'score': 0.62358373}]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Hay muchas maneras de cocinar pollo, dependiendo de la parte del pollo y el resultado deseado. Algunas de las formas más comunes incluyen:\n",
            "\n",
            "*   **A la plancha:** Ideal para filetes de pechuga, ya que son delgados y se cocinan rápidamente.\n",
            "*   **En brochetas:** Se pueden usar trozos de pollo en brochetas con verduras.\n",
            "*   **Frito:** Una opción popular para alitas o trozos de pollo empanizados.\n",
            "*   **Asado/Al horno:** Se puede asar un pollo entero o partes de pollo en el horno, a menudo con patatas u otras verduras.\n",
            "*   **Guisado/En salsa:** Cocinar el pollo a fuego lento en una salsa, lo que lo hace muy tierno y sabroso.\n",
            "*   **A la parrilla/Al carbón:** Para un sabor ahumado, se puede cocinar el pollo en una parrilla.\n",
            "\n",
            "Para muchas de estas preparaciones, un paso inicial común es salpimentar el pollo y dorarlo a fuego fuerte antes de continuar con la cocción.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Hay muchas maneras de cocinar pollo, dependiendo de la parte del pollo y el resultado deseado. Algunas de las formas más comunes incluyen:\n",
            "\n",
            "*   **A la plancha:** Ideal para filetes de pechuga, ya que son delgados y se cocinan rápidamente.\n",
            "*   **En brochetas:** Se pueden usar trozos de pollo en brochetas con verduras.\n",
            "*   **Frito:** Una opción popular para alitas o trozos de pollo empanizados.\n",
            "*   **Asado/Al horno:** Se puede asar un pollo entero o partes de pollo en el horno, a menudo con patatas u otras verduras.\n",
            "*   **Guisado/En salsa:** Cocinar el pollo a fuego lento en una salsa, lo que lo hace muy tierno y sabroso.\n",
            "*   **A la parrilla/Al carbón:** Para un sabor ahumado, se puede cocinar el pollo en una parrilla.\n",
            "\n",
            "Para muchas de estas preparaciones, un paso inicial común es salpimentar el pollo y dorarlo a fuego fuerte antes de continuar con la cocción.\n"
          ]
        }
      ],
      "source": [
        "response = agent_executor.invoke({\"input\": \"Cómo puedo cocinar un pollo?\"})\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mientras que la tool de Wikipedia debe emplearse para responder preguntas sobre un tópico específico, como personas, lugares, eventos históricos, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: Lionel Messi\u001b[0m\u001b[33;1m\u001b[1;3mPage: Lionel Messi\n",
            "Summary: Lionel Andrés \"Leo\" Messi (Spanish pronunciation: [ljoˈnel anˈdɾes ˈmesi\u001b[0m\u001b[32;1m\u001b[1;3mThought: The full summary from Wikipedia clearly states that Lionel Messi \"is an Argentine professional footballer\" and \"captains the Argentina national team.\" It also mentions he \"left his home country of Argentina\".\n",
            "Final Answer: Lionel Messi es de nacionalidad argentina.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Lionel Messi es de nacionalidad argentina.\n"
          ]
        }
      ],
      "source": [
        "response = agent_executor.invoke({\"input\": \"De qué nacionalidad es Lionel Messi?\"})\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZbDTYiogquv"
      },
      "source": [
        "### **2.3 Multi Agente (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
        "\" width=\"450\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsección es encapsular las funcionalidades creadas en una solución multiagente con un **supervisor**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-iUfH0WvI6m"
      },
      "source": [
        "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
        "\n",
        "Transforme la solución RAG de la sección 2.1 y el agente de la sección 2.2 a *tools* (una tool por cada uno)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "pw1cfTtvv1AZ"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def search_bias_query(query: str) -> str:\n",
        "    \"\"\"Asks a query to an expert about Biases in LLMs.\"\"\"\n",
        "    return base_rag_chain.invoke(query)\n",
        "\n",
        "@tool\n",
        "def search_general_query(query: str) -> str:\n",
        "    \"\"\"Asks a query about a general topic.\"\"\"\n",
        "    return agent_executor.invoke({\"input\": query})[\"output\"]\n",
        "\n",
        "multiagent_tools = [search_bias_query, search_general_query]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQYNjT_0vPCg"
      },
      "source": [
        "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
        "\n",
        "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqfx0WbMCfVG",
        "outputId": "097a27ba-17e7-44cf-d8b9-0134ea68d358"
      },
      "outputs": [],
      "source": [
        "supervisor_agent = create_react_agent(llm, multiagent_tools, react_prompt) # primero inicializamos el agente ReAct\n",
        "supervisor = AgentExecutor(agent=supervisor_agent, tools=multiagent_tools, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea3zWlvyvY7K"
      },
      "source": [
        "#### **2.3.3 Verificación de respuestas (0.25 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. ¿Cómo varían las respuestas bajo este enfoque?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6_1t0zkgv1qW",
        "outputId": "7feca4e0-e716-4020-e46c-3518e2ac4385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: search_general_query\n",
            "Action Input: What are social biases?\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: social biases\u001b[0m\u001b[33;1m\u001b[1;3mPage: List of cognitive biases\n",
            "Summary: Cognitive biases are systematic patterns of deviation from n\u001b[0m\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: social bias\u001b[0m\u001b[33;1m\u001b[1;3mPage: Social-desirability bias\n",
            "Summary: In social science research social-desirability bias is a typ\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: what are social biases definition\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Social Biases | Free Essay Example for Students - Aithor', 'url': 'https://aithor.com/essay-examples/social-biases', 'content': 'A social bias is a process in which social groups can be categorized, often in a stereotypical way, and are treated differently and in an unfair manner as a result. There are many forms of social bias, including the most well-known form, which is prejudice. Prejudice is an unjust and usually negative attitude towards a group and its individual members. It often involves labeling, and this can be the starting point for more extreme forms of social bias. Discrimination is the action that [...] themselves as belonging. Social biases tend to have a self-perpetuating quality, in that the person who holds a biased belief about a certain group will likely behave in a way that is consistent with that belief, thereby appearing to confirm it in the eyes of themselves and others. Such behavior can also lead the person to interpret ambiguous actions by a member of the group in a way that is consistent with their biases. In these ways, social biases can lead to the overgeneralization of certain [...] Social biases arise when people have unconscious beliefs about various social groups, which influence behavior toward members of those groups. Because many of these beliefs are largely inaccurate and/or negative, social biases can result in unfair discrimination against certain groups. Common examples of social biases are those specifically associated with age, sex, race, and criminality, though people can be biased based on any assumed characteristic of a group to which they do not see', 'score': 0.8978479}]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Social biases are processes where social groups are categorized, often stereotypically, leading to unfair and differential treatment. These biases often stem from unconscious beliefs about various social groups, which can influence behavior and result in unfair discrimination. Prejudice and discrimination are common forms of social bias.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mSocial biases are processes where social groups are categorized, often stereotypically, leading to unfair and differential treatment. These biases often stem from unconscious beliefs about various social groups, which can influence behavior and result in unfair discrimination. Prejudice and discrimination are common forms of social bias.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Social biases are processes that involve categorizing social groups, often through stereotypes, which can lead to unfair and differential treatment. They frequently originate from unconscious beliefs about various social groups, influencing behavior and resulting in unfair discrimination. Prejudice and discrimination are common manifestations of social bias.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Question: What are social biases? \n",
            "Answer: Social biases are processes that involve categorizing social groups, often through stereotypes, which can lead to unfair and differential treatment. They frequently originate from unconscious beliefs about various social groups, influencing behavior and resulting in unfair discrimination. Prejudice and discrimination are common manifestations of social bias.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: search_bias_query\n",
            "Action Input: embedding-based metrics for measuring bias in LLMs\u001b[0m\u001b[36;1m\u001b[1;3mEmbedding-based metrics for measuring bias in LLMs utilize the dense vector representations of the model, which are typically contextual sentence embeddings, to measure bias. These metrics leverage embeddings for bias evaluation.\u001b[0m\u001b[32;1m\u001b[1;3mAction: search_bias_query\n",
            "Action Input: specific embedding-based metrics for LLM bias\u001b[0m\u001b[36;1m\u001b[1;3mBased on the provided information, the text introduces \"Embedding-based metrics\" as a category for measuring bias using dense vector representations, typically contextual sentence embeddings. It states that a section (3.3) will discuss these metrics and mentions examples in Figures 3–5, but it does not provide the names of any specific embedding-based metrics.\u001b[0m\u001b[32;1m\u001b[1;3mAction: search_general_query\n",
            "Action Input: specific embedding-based metrics for measuring bias in LLMs\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: specific embedding-based metrics for measuring bias in LLMs\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias Detection in LLM Outputs: Statistical Approaches', 'url': 'https://machinelearningmastery.com/bias-detection-in-llm-outputs-statistical-approaches/', 'content': 'Embedding-based testing is a technique for identifying and measuring bias within the LLM embedding model, specifically in its latent', 'score': 0.85797083}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: embedding-based bias metrics LLMs\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias Detection in LLM Outputs: Statistical Approaches', 'url': 'https://machinelearningmastery.com/bias-detection-in-llm-outputs-statistical-approaches/', 'content': 'Embedding-based testing is a technique for identifying and measuring bias within the LLM embedding model, specifically in its latent representations. We know that an embedding is a high-dimension vector that encodes semantic relationships between words in the latent space. By examining the relationships, we can understand the biases from a model that came inherently from training data.', 'score': 0.882276}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: specific embedding bias metrics for LLMs\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias Detection in LLM Outputs: Statistical Approaches', 'url': 'https://machinelearningmastery.com/bias-detection-in-llm-outputs-statistical-approaches/', 'content': 'Embedding-based testing is a technique for identifying and measuring bias within the LLM embedding model, specifically in its latent representations. We know that an embedding is a high-dimension vector that encodes semantic relationships between words in the latent space. By examining the relationships, we can understand the biases from a model that came inherently from training data.', 'score': 0.77055156}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: named embedding-based bias metrics for LLMs\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias and Fairness in Large Language Models: A Survey - arXiv', 'url': 'https://arxiv.org/html/2309.00770v2', 'content': 'Table 3: Taxonomy of Evaluation Metrics for Bias Evaluation in LLMs. We summarize metrics that measure bias using embeddings, model-assigned probabilities, or generated text. The data structure describes the input to the model required to compute the metrics, and 𝒟𝒟\\\\\\\\mathcal{D}caligraphic\\\\_D indicates if the metric was introduced with an accompanying dataset. W𝑊Witalic\\\\_W is the set of neutral words; Aisubscript𝐴𝑖A\\\\_{i}italic\\\\_A start\\\\_POSTSUBSCRIPT italic\\\\_i end\\\\_POSTSUBSCRIPT is the set of [...] Word Embedding222Static word embeddings are not used with LLMs, but we include the word embedding metric WEAT for completeness given its relevance to sentence embedding metrics. (§[3.3.1](https://arxiv.org/html/2309.00770v2#S3.SS3.SSS1 \"3.3.1 Word Embedding Metrics ‣ 3.3 Embedding-Based Metrics ‣ 3 Taxonomy of Metrics for Bias Evaluation ‣ Bias and Fairness in Large Language Models: A Survey\")): Compute distances in the embedding space\\n        \\n        Report issue for preceding element [...] Most bias evaluation metrics for LLMs can be categorized by _what_ they use from the model such as the _embeddings_, _probabilities_, or _generated text_. As such, we propose an intuitive taxonomy based on this categorization:\\n\\nReport issue for preceding element', 'score': 0.84183896}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: specific embedding-based bias metrics for large language models\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias in Large Language Models: Origin, Evaluation, and Mitigation', 'url': 'https://arxiv.org/html/2411.10915v1', 'content': 'Counterfactual Testing, Stereotype Detection, Sentiment and Toxicity Analysis, Acceptance and Rejection Rates, and Embedding-Based Metrics.', 'score': 0.77055156}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: WEAT for LLMs or sentence embedding bias metrics\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias and Fairness in Large Language Models: A Survey - arXiv', 'url': 'https://arxiv.org/html/2309.00770v2', 'content': 'Word Embedding222Static word embeddings are not used with LLMs, but we include the word embedding metric WEAT for completeness given its relevance to sentence embedding metrics. (§[3.3.1](https://arxiv.org/html/2309.00770v2#S3.SS3.SSS1 \"3.3.1 Word Embedding Metrics ‣ 3.3 Embedding-Based Metrics ‣ 3 Taxonomy of Metrics for Bias Evaluation ‣ Bias and Fairness in Large Language Models: A Survey\")): Compute distances in the embedding space\\n        \\n        Report issue for preceding element [...] Table 3: Taxonomy of Evaluation Metrics for Bias Evaluation in LLMs. We summarize metrics that measure bias using embeddings, model-assigned probabilities, or generated text. The data structure describes the input to the model required to compute the metrics, and 𝒟𝒟\\\\\\\\mathcal{D}caligraphic\\\\_D indicates if the metric was introduced with an accompanying dataset. W𝑊Witalic\\\\_W is the set of neutral words; Aisubscript𝐴𝑖A\\\\_{i}italic\\\\_A start\\\\_POSTSUBSCRIPT italic\\\\_i end\\\\_POSTSUBSCRIPT is the set of [...] cd=\"ambiguous\" id=\"S3.T3.43.9.1.1.1.m1.2.2.4.3.1.cmml\" xref=\"S3.T3.43.9.1.1.1.m1.2.2.4.3\">subscript</csymbol><ci id=\"S3.T3.43.9.1.1.1.m1.2.2.4.3.2.cmml\" xref=\"S3.T3.43.9.1.1.1.m1.2.2.4.3.2\">𝑣</ci><ci id=\"S3.T3.43.9.1.1.1.m1.2.2.4.3.3.cmml\" xref=\"S3.T3.43.9.1.1.1.m1.2.2.4.3.3\">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.43.9.1.1.1.m1.4c\">f(S_{A},S_{W})=\\\\tfrac{\\\\Sigma_{i=1}^{N}v_{i}\\\\textrm{WEAT}(S_{A_{i}},S_{W_{i}})}%', 'score': 0.8286204}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: \"embedding-based bias metrics\" LLMs specific names\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'How to measure the Bias and Fairness of LLM?', 'url': 'https://substack.com/home/post/p-156509065?utm_campaign=post&utm_medium=web', 'content': 'Embedding-based metrics use embeddings to detect bias in LLMs. Specifically, these metrics compute distances in the embedding space between', 'score': 0.7520312}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I have searched for specific embedding-based metrics for measuring bias in LLMs. The results consistently point to the concept of \"embedding-based testing\" which involves examining relationships and computing distances in the latent space of embeddings. One specific metric mentioned is WEAT (Word Embedding Association Test), which is acknowledged for its relevance to sentence embedding metrics in LLMs, even though it originated for static word embeddings. The search results also mention that most bias evaluation metrics for LLMs can be categorized by what they use from the model (embeddings, probabilities, or generated text). While the general approach of \"computing distances in the embedding space\" is highlighted, WEAT is the most specific named metric found in the context of embedding-based bias measurement for LLMs. I will synthesize this information to answer the question.\n",
            "\n",
            "Final Answer: One specific embedding-based metric for measuring bias in LLMs is the **Word Embedding Association Test (WEAT)**. While originally developed for static word embeddings, it is considered relevant for sentence embedding metrics in the context of LLMs. Generally, embedding-based metrics for LLMs involve computing distances and examining relationships within the embedding space to identify and quantify biases present in the model's latent representations.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mOne specific embedding-based metric for measuring bias in LLMs is the **Word Embedding Association Test (WEAT)**. While originally developed for static word embeddings, it is considered relevant for sentence embedding metrics in the context of LLMs. Generally, embedding-based metrics for LLMs involve computing distances and examining relationships within the embedding space to identify and quantify biases present in the model's latent representations.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: One specific embedding-based metric for measuring bias in LLMs is the **Word Embedding Association Test (WEAT)**. These metrics generally involve computing distances and examining relationships within the embedding space to identify and quantify biases present in the model's latent representations.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs? \n",
            "Answer: One specific embedding-based metric for measuring bias in LLMs is the **Word Embedding Association Test (WEAT)**. These metrics generally involve computing distances and examining relationships within the embedding space to identify and quantify biases present in the model's latent representations.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: search_bias_query\n",
            "Action Input: Bias mitigation techniques LLMs pre-processing stage\u001b[0m\u001b[36;1m\u001b[1;3mBias mitigation techniques at the pre-processing stage in LLMs include:\n",
            "*   Data Augmentation\n",
            "*   Data Filtering & Reweighting\n",
            "*   Data Generation\n",
            "*   Instruction Tuning\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Techniques for bias mitigation in LLMs that intervene in the pre-processing stage include Data Augmentation, Data Filtering & Reweighting, Data Generation, and Instruction Tuning.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage? \n",
            "Answer: Techniques for bias mitigation in LLMs that intervene in the pre-processing stage include Data Augmentation, Data Filtering & Reweighting, Data Generation, and Instruction Tuning.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "for q in questions:\n",
        "    response = supervisor.invoke({\"input\": q[0]})\n",
        "    print(\"Question:\", q[0], \"\\nAnswer:\", response[\"output\"])\n",
        "    time.sleep(30)  # Para prevenir que se caiga por la cuota del free tier de Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: search_general_query\n",
            "Action Input: Cómo cocinar un pollo\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: Cómo cocinar un pollo\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Pollo - 74,888 recetas caseras- Cookpad', 'url': 'https://cookpad.com/eeuu/buscar/pollo', 'content': '*   \\n[Pollo en cazuela](https://cookpad.com/eeuu/recetas/17014457)\\n-------------------------------------------------------------  Guarda esta receta para encontrarla más fácilmente cuando la quieras cocinar.   [](https://cookpad.com/eeuu/buscar/pollo# \"Cerrar\")          muslos de pollo • Sal • Pimienta • Ajo • Jugo de un limón o naranja agria • Curry • Romero • Vino seco • Aceite vegetal • Puré de tomate   \\n\\n    *   1h y 30 min\\n    *   3 o 4 raciones [...] ------------------------------------------------------------------------------------------------------------------------------------  Guarda esta receta para encontrarla más fácilmente cuando la quieras cocinar.   [](https://cookpad.com/eeuu/buscar/pollo# \"Cerrar\")          muslos previamente hervidos con sal • huevos • ajos grandes • cebolla pequeña • cebollín • Cilantro • especias: comino, paprika, orégano y especias italianas (las de tu preferencia) • Sal    ![Image 81: Eddy Moreno de [...] *   \\n[Pollo con verduras](https://cookpad.com/eeuu/recetas/16985032)\\n---------------------------------------------------------------  Guarda esta receta para encontrarla más fácilmente cuando la quieras cocinar.   [](https://cookpad.com/eeuu/buscar/pollo# \"Cerrar\")          pechuga de pollo • Verduras de tu preferencia finamente picado • Sal • ajo • Pimienta • aceite • leche • laurel • agua   \\n\\n    *   40 minutos\\n    *   3 porciones', 'score': 0.65940565}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: Cómo cocinar pollo métodos básicos\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Clásico pollo rostizado | Recetas - Cook for Your Life', 'url': 'https://www.cookforyourlife.org/es/recetas/clasico-pollo-rostizado/', 'content': 'Procedimiento · Precalienta el horno a 400 grados. · Retire cualquier paquete de menudencias del interior del pollo. · Seque el pollo con una toalla de papel.', 'score': 0.48616135}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: Métodos básicos para cocinar pollo\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Conoce más del pollo y crea deliciosos platos. | Recetas Nestlé', 'url': 'https://www.recetasnestle.com.mx/escuela-sabor/recetas-caseras/cocinar-con-pollo', 'content': 'Por esta y otras razones el pollo es uno de los ingredientes preferidos en todos los hogares gracias a sus infinitas posibilidades en la cocina.\\n\\nA continuación, te mostramos los métodos de cocción más utilizados en el pollo\\n\\n### **ESTOFADO**\\n\\nUn tipo de cocción prolongada a fuego lento, el pollo queda más meloso y conservan todo el sabor de los ingredientes que agregues a la mezcla.\\n\\n### **A LA PARRILLA** [...] Por esta y otras razones el pollo es uno de los ingredientes preferidos en todos los hogares gracias a sus infinitas posibilidades en la cocina.\\n\\nA continuación, te mostramos los métodos de cocción más utilizados en el pollo\\n\\n### **ESTOFADO**\\n\\nUn tipo de cocción prolongada a fuego lento, el pollo queda más meloso y conservan todo el sabor de los ingredientes que agregues a la mezcla.\\n\\n### **A LA PARRILLA** [...] Por esta y otras razones el pollo es uno de los ingredientes preferidos en todos los hogares gracias a sus infinitas posibilidades en la cocina.\\n\\nA continuación, te mostramos los métodos de cocción más utilizados en el pollo\\n\\n### **ESTOFADO**\\n\\nUn tipo de cocción prolongada a fuego lento, el pollo queda más meloso y conservan todo el sabor de los ingredientes que agregues a la mezcla.\\n\\n### **A LA PARRILLA**', 'score': 0.70214266}]\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: Para cocinar pollo, existen varios métodos populares y deliciosos:\n",
            "\n",
            "1.  **Estofado:** Este método implica una cocción prolongada a fuego lento, lo que hace que el pollo quede muy tierno y meloso, absorbiendo todos los sabores de los ingredientes añadidos.\n",
            "2.  **A la parrilla:** Cocinar el pollo a la parrilla le da un sabor ahumado y una textura jugosa por dentro y ligeramente crujiente por fuera.\n",
            "3.  **Rostizado (Asado al horno):** Para un pollo rostizado clásico, se precalienta el horno a una temperatura alta (como 400 grados Fahrenheit o 200 grados Celsius). Es importante retirar cualquier paquete de menudencias del interior del pollo y secarlo bien con una toalla de papel antes de sazonar y asar.\n",
            "\n",
            "Además de estos métodos, el pollo se puede preparar de muchas otras maneras, como frito, salteado, hervido, o en cazuela, utilizando diferentes condimentos y acompañamientos.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mPara cocinar pollo, existen varios métodos populares y deliciosos:\n",
            "\n",
            "1.  **Estofado:** Este método implica una cocción prolongada a fuego lento, lo que hace que el pollo quede muy tierno y meloso, absorbiendo todos los sabores de los ingredientes añadidos.\n",
            "2.  **A la parrilla:** Cocinar el pollo a la parrilla le da un sabor ahumado y una textura jugosa por dentro y ligeramente crujiente por fuera.\n",
            "3.  **Rostizado (Asado al horno):** Para un pollo rostizado clásico, se precalienta el horno a una temperatura alta (como 400 grados Fahrenheit o 200 grados Celsius). Es importante retirar cualquier paquete de menudencias del interior del pollo y secarlo bien con una toalla de papel antes de sazonar y asar.\n",
            "\n",
            "Además de estos métodos, el pollo se puede preparar de muchas otras maneras, como frito, salteado, hervido, o en cazuela, utilizando diferentes condimentos y acompañamientos.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Para cocinar pollo, tienes varias opciones populares:\n",
            "\n",
            "1.  **Estofado:** Cocción lenta que hace que el pollo quede muy tierno y absorba bien los sabores.\n",
            "2.  **A la parrilla:** Le da un sabor ahumado y una textura jugosa por dentro y ligeramente crujiente por fuera.\n",
            "3.  **Rostizado (Asado al horno):** Se precalienta el horno a una temperatura alta (ej. 200°C o 400°F). Es importante secar bien el pollo y retirar cualquier paquete de menudencias antes de sazonar y asar.\n",
            "\n",
            "También puedes cocinarlo frito, salteado, hervido o en cazuela, dependiendo de la receta que prefieras.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Para cocinar pollo, tienes varias opciones populares:\n",
            "\n",
            "1.  **Estofado:** Cocción lenta que hace que el pollo quede muy tierno y absorba bien los sabores.\n",
            "2.  **A la parrilla:** Le da un sabor ahumado y una textura jugosa por dentro y ligeramente crujiente por fuera.\n",
            "3.  **Rostizado (Asado al horno):** Se precalienta el horno a una temperatura alta (ej. 200°C o 400°F). Es importante secar bien el pollo y retirar cualquier paquete de menudencias antes de sazonar y asar.\n",
            "\n",
            "También puedes cocinarlo frito, salteado, hervido o en cazuela, dependiendo de la receta que prefieras.\n"
          ]
        }
      ],
      "source": [
        "response = supervisor.invoke({\"input\": \"Cómo puedo cocinar un pollo?\"})\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: search_general_query\n",
            "Action Input: What is Lionel Messi's nationality?\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: Lionel Messi\u001b[0m\u001b[33;1m\u001b[1;3mPage: Lionel Messi\n",
            "Summary: Lionel Andrés \"Leo\" Messi (Spanish pronunciation: [ljoˈnel anˈdɾes ˈmesi\u001b[0m\u001b[32;1m\u001b[1;3mThought: The user is asking for Lionel Messi's nationality. I have used the Wikipedia tool and received a snippet of the summary. While the snippet itself does not explicitly state his nationality, it is common knowledge and typically the first piece of information in a Wikipedia summary for a person. I will assume that the full summary from Wikipedia would contain this information, and based on general knowledge, his nationality is Argentinian.\n",
            "Final Answer: Lionel Messi's nationality is Argentinian.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mLionel Messi's nationality is Argentinian.\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: Es argentino.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Es argentino.\n"
          ]
        }
      ],
      "source": [
        "response = supervisor.invoke({\"input\": \"De qué nacionalidad es Lionel Messi?\"})\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las respuestas del enfoque 2.1.4 cambian dado que la pregunta 2 no se responde con la herramienta de RAG, sino que al ser una pregunta más general se consulta con la herramienta del agente. Además, ahora que el agente de RAG no responde directamente, el agente supervisor utiliza su respuesta y la entrega en una redacción distinta. Por otro lado, las respuestas del enfoque 2.2.4 utilizan la herramienta del agente, como se esperaba, y entrega respuestas similares a las generadas previamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb8bdAmYvgwn"
      },
      "source": [
        "#### **2.3.4 Análisis (0.25 puntos)**\n",
        "\n",
        "¿Qué diferencias tiene este enfoque con la solución *Router* vista en clases? Nombre al menos una ventaja y desventaja."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAUlJxqoLK5r"
      },
      "source": [
        "La diferencia es que el agente, en vez de decidir una \"categoría\" que después es parseada para llamar a un segundo agente que resuelve la pregunta, usa a los agentes como herramientas. Una ventaja de esto es que puede llamar a ambos agentes en una sola ejecución si lo considera pertinente, mientras que una desventaja es que realiza más ejecuciones del LLM, porque ahora el supervisor también tiene un template tipo ReAct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JWVSuWiZ8Mj"
      },
      "source": [
        "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
        "\n",
        "- Pregunta 1: \"Hola! mi nombre es Sebastián\"\n",
        "  - Respuesta esperada: \"Hola Sebastián! ...\"\n",
        "- Pregunta 2: \"Cual es mi nombre?\"\n",
        "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
        "  - **Respuesta esperada: \"Tu nombre es Sebastián\"**\n",
        "\n",
        "Para solucionar esto, se les solicita agregar un componente de **memoria** a la solución entregada en el punto 2.3.\n",
        "\n",
        "**Nota: El Bonus es válido <u>sólo para la sección 2 de Large Language Models.</u>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "K6Y7tIPJLPfB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/felipe/.pyenv/versions/lab11/lib/python3.11/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Extendemos el prompt de React para incorporar la interacción previa\n",
        "memory_prompt = hub.pull(\"hwchase17/react\")\n",
        "memory_prompt.template = 'Previous interaction: {memory}\\n' + memory_prompt.template\n",
        "memory_prompt.input_variables.append('memory')\n",
        "\n",
        "memory_agent = create_react_agent(llm, multiagent_tools, memory_prompt) # primero inicializamos el agente ReAct\n",
        "memory_agent_executor = AgentExecutor(agent=memory_agent, tools=multiagent_tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: ¡Hola Felipe! Mucho gusto.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "¡Hola Felipe! Mucho gusto.\n"
          ]
        }
      ],
      "source": [
        "memory = ''\n",
        "\n",
        "def invoke_agent_with_memory(input, memory):\n",
        "    response = memory_agent_executor.invoke({\"input\": input, \"memory\": memory})\n",
        "    memory += f'User: {input}\\n Agent:{response[\"output\"]}'\n",
        "    print(response[\"output\"])\n",
        "    return memory\n",
        "\n",
        "memory = invoke_agent_with_memory(\"Hola, soy Felipe!\", memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: Tu nombre es Felipe.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Tu nombre es Felipe.\n"
          ]
        }
      ],
      "source": [
        "memory = invoke_agent_with_memory(\"Cuál es mi nombre?\", memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFc3jBT5g0kT"
      },
      "source": [
        "### **2.5 Despliegue (0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a través de `gradio`, una librería especializada en el levantamiento rápido de demos basadas en ML.\n",
        "\n",
        "Primero instalamos la librería:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "T8TsvnCPbkIA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJBztEUovKsF"
      },
      "source": [
        "Luego sólo deben ejecutar el siguiente código e interactuar con la interfaz a través del notebook o del link generado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3KedQSvg1-n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7863\n",
            "* Running on public URL: https://6934e35b6a75d4f859.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://6934e35b6a75d4f859.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: ¡Hola! ¿En qué puedo ayudarte hoy?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: ¡Hola, Felipe! Es un placer conocerte. ¿Hay algo en lo que pueda ayudarte hoy?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: Te llamas Felipe.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "def agent_response(message, history):\n",
        "  '''\n",
        "  Función para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
        "  '''\n",
        "  # get chatbot response\n",
        "  response = memory_agent_executor.invoke({\"input\": message, \"memory\": history})[\"output\"] # rellenar con la respuesta de su chat\n",
        "\n",
        "  # assert\n",
        "  assert type(response) == str, \"output de route_question debe ser string\"\n",
        "\n",
        "  # \"streaming\" response\n",
        "  for i in range(len(response)):\n",
        "    time.sleep(0.015)\n",
        "    yield response[: i+1]\n",
        "\n",
        "gr.ChatInterface(\n",
        "    agent_response,\n",
        "    type=\"messages\",\n",
        "    title=\"Chatbot MDS7202\", # Pueden cambiar esto si lo desean\n",
        "    description=\"Hola! Soy un chatbot muy útil :)\", # también la descripción\n",
        "    theme=\"soft\",\n",
        "    ).launch(\n",
        "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
        "        debug = False,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80VmXCmnfXnJ"
      },
      "source": [
        "# Conclusión\n",
        "Éxito!\n",
        "<center>\n",
        "<img src =\"https://media.tenor.com/MRQgxcelAV8AAAAM/perry-the-platypus-phineas-and-ferb.gif\" width = 400 />"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lab11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0678c1f060f54ad289eeb8cc079a4739": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a115967f34d4dcebbf328cc16ecb845": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0678c1f060f54ad289eeb8cc079a4739",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">10,178/10,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:21</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">469 it/s</span> ]\n</pre>\n",
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10,178/10,000 \u001b[0m [ \u001b[33m0:00:21\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m469 it/s\u001b[0m ]\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "be65422cf0be4c90bab935bc012c609d": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_cabdbad743c54b05bdbe6e0606611f8f",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">100,341/100,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:06:32</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">261 it/s</span> ]\n</pre>\n",
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100,341/100,000 \u001b[0m [ \u001b[33m0:06:32\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m261 it/s\u001b[0m ]\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "cabdbad743c54b05bdbe6e0606611f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
