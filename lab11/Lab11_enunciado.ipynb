{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyPTffTLug7i"
      },
      "source": [
        "# **Laboratorio 11: Pienso, luego predigo 游눠**\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci칩n Cient칤fica para Ciencia de Datos - Oto침o 2025</strong></center>\n",
        "\n",
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Stefano Schiappacasse, Sebasti치n Tinoco\n",
        "- Auxiliares: Melanie Pe침a, Valentina Rojas\n",
        "- Ayudantes: Angelo Mu침oz, Valentina Z칰침iga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy6ikgVYzghB"
      },
      "source": [
        "### **Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser치n revisados**\n",
        "\n",
        "- Nombre de alumno 1: Felipe Hern치ndez M.\n",
        "- Nombre de alumno 2: Brandon Pe침a H."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMJ-owchzjFf"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Enlace](https://github.com/brandonHaipas/MDS7202-Lab-Prog-Ciencia-de-Datos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUuwsXrKzmkK"
      },
      "source": [
        "## **Temas a tratar**\n",
        "\n",
        "- Reinforcement Learning\n",
        "- Large Language Models\n",
        "\n",
        "## **Reglas:**\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 6 d칤as de plazo con descuento de 1 punto por d칤a. Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser치 debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est칠n en u-cursos no ser치n revisados. Recuerden que el repositorio tambi칠n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser치n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente.\n",
        "\n",
        "### **Objetivos principales del laboratorio**\n",
        "\n",
        "- Resoluci칩n de problemas secuenciales usando Reinforcement Learning\n",
        "- Habilitar un Chatbot para entregar respuestas 칰tiles usando Large Language Models.\n",
        "\n",
        "El laboratorio deber치 ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m치ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m치s eficientes que los iteradores nativos sobre DataFrames."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmHHQ9BuyAG"
      },
      "source": [
        "## **1. Reinforcement Learning (2.0 puntos)**\n",
        "\n",
        "En esta secci칩n van a usar m칠todos de RL para resolver dos problemas interesantes: `Blackjack` y `LunarLander`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOcejYb6uzOO",
        "outputId": "fdcec8b0-1c49-4de7-d947-9e484dffda50"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq gymnasium stable_baselines3\n",
        "!pip install -qqq swig\n",
        "!pip install -qqq \"gymnasium[box2d]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBPet_Mq8dX9"
      },
      "source": [
        "### **1.1 Blackjack (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://www.recreoviral.com/wp-content/uploads/2016/08/s3.amazonaws.com-Math.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "La idea de esta subsecci칩n es que puedan implementar m칠todos de RL y as칤 generar una estrategia para jugar el cl치sico juego Blackjack y de paso puedan ~~hacerse millonarios~~ aprender a resolver problemas mediante RL.\n",
        "\n",
        "Comencemos primero preparando el ambiente. El siguiente bloque de c칩digo transforma las observaciones del ambiente a `np.array`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LpZ8bBKk9ZlU"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.spaces import MultiDiscrete\n",
        "import numpy as np\n",
        "\n",
        "class FlattenObservation(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(FlattenObservation, self).__init__(env)\n",
        "        self.observation_space = MultiDiscrete(np.array([32, 11, 2]))\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.array(observation).flatten()\n",
        "\n",
        "# Create and wrap the environment\n",
        "env = gym.make(\"Blackjack-v1\")\n",
        "env = FlattenObservation(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ6J1_-Y9nHO"
      },
      "source": [
        "#### **1.1.1 Descripci칩n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci칩n sobre el ambiente [Blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/) y su formulaci칩n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5i1Wt1p770x"
      },
      "source": [
        "El ambiente de `blackjack` contiene la implementaci칩n del juego de Blackjack como un problema de RL. El objetivo del juego es ganarle al _dealer_ consiguiendo cartas cuyo puntaje sume un valor m치s cercano a 21 (sin superar el 21) que las cartas del _dealer_.\n",
        "\n",
        "El puntaje de cada carta se describe a continuaci칩n:\n",
        "- Los _ases_ pueden contar como 11 o 1.\n",
        "- Las cartas J, Q, K tienen un valor de 10.\n",
        "- Las cartas num칠ricas (2 a 10) tienen un valor equivalente a su n칰mero.\n",
        "\n",
        "El juego comienza con el _dealer_ sacando dos cartas: una visible y la otra boca abajo.\n",
        "\n",
        "En cada paso del juego, el jugador puede solicitar _(hit)_ una nueva carta hasta que decida quedarse _(stick)_ con las que posee actualmente. Si al solicitar una nueva carta el jugador supera el valor 21, pierde autom치ticamente.\n",
        "\n",
        "Una vez el jugador decide quedarse, el _dealer_ revela su carta boca abajo y saca nuevas cartas hasta que la suma de sus puntos sea 17 o mayor, perdiendo si llega a superar el valor 21.\n",
        "\n",
        "La formulaci칩n del problema como un _Markov Decision Process_ consiste de los siguientes componentes:\n",
        "- Estados: Cada observaci칩n consiste de una 3-tupla $(p, d, a)$, donde $p$ corresponde a la suma de puntos actual del jugador, $d$ el puntaje de la carta visible del _dealer_ (un valor de 1 a 10, donde 1 es un _as_) y $a$ un valor 1 o 0 indicando si el jugador posee o no una carta _as_, respectivamente. Cada uno de estos valores es un n칰mero entero.\n",
        "- Acciones: El espacio de acci칩n es de dimensi칩n 1, cuyos posibles valores son:\n",
        "    - 0: Quedarse (stick)\n",
        "    - 1: Solicitar una nueva carta (hit)\n",
        "- Recompensas:\n",
        "    - Ganar el juego: +1 o +1.5 si es un _natural blackjack_ (ganar por comenzar con un _as_ y un 10, el uso del puntaje adicional para este caso es opcional y requiere el uso del argumento `natural=True`)\n",
        "    - Perder el juego: -1\n",
        "    - Empatar el juego: 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmcX6bRC9agQ"
      },
      "source": [
        "#### **1.1.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci칩n 5000 veces y reporte el promedio y desviaci칩n de las recompensas. 쮺칩mo calificar칤a el performance de esta pol칤tica? 쮺칩mo podr칤a interpretar las recompensas obtenidas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p2PrLLR9yju",
        "outputId": "00c63650-dd2f-4890-cc5f-ec209b07cd78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recompensa promedio: -0.3866\n",
            "Desviaci칩n est치ndar de recompensas: 0.8999669105028251\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(0)\n",
        "\n",
        "n_simulations = 5000\n",
        "action_space = [0, 1]\n",
        "rewards = []\n",
        "\n",
        "for episode in range(n_simulations):\n",
        "    env.reset(seed=random.randint(1, 10000))\n",
        "    end = False\n",
        "\n",
        "    while not end:\n",
        "        action = random.choice(action_space)\n",
        "        state, reward, done, truncated, info = env.step(action)\n",
        "        end = done | truncated\n",
        "    rewards.append(reward)\n",
        "\n",
        "print('Recompensa promedio:', np.mean(rewards))\n",
        "print('Desviaci칩n est치ndar de recompensas:', np.std(rewards))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance de esta pol칤tica aleatoria no es buena, en promedio el agente tiene una recompensa negativa de -0.3866, es decir, pierde 2/3 de las veces que no empata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEO_dY4x_SJu"
      },
      "source": [
        "#### **1.1.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `Blackjack`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "m9JsFA1wGmnH",
        "outputId": "c775b65d-b70c-494a-85ca-f6b0a9088557"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d91e1b286d4427fb5c21f96818a371b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.dqn.dqn.DQN at 0x7fe38a7d7cd0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from stable_baselines3 import DQN\n",
        "\n",
        "# init agent\n",
        "model = DQN(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# train the agent and display a progress bar\n",
        "model.learn(total_timesteps=int(2e5), progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-bpdb8wZID1"
      },
      "source": [
        "#### **1.1.4 Evaluaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.1.2 pero utilizando el modelo entrenado. 쮺칩mo es el performance de su agente? 쮼s mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-d7d8GFf7F6",
        "outputId": "76b239bc-bc68-4464-f7fc-017f67f54124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recompensa promedio: -0.054\n",
            "Desviaci칩n est치ndar de recompensas: 0.9458773704873165\n"
          ]
        }
      ],
      "source": [
        "n_simulations = 5000\n",
        "rewards = []\n",
        "\n",
        "for episode in range(n_simulations):\n",
        "    end = False\n",
        "    result = None\n",
        "    state, info = env.reset(seed=random.randint(1, 10000))\n",
        "\n",
        "    while not end:\n",
        "        action, _states = model.predict(state, deterministic=True)\n",
        "        action = action.item()\n",
        "        state, reward, done, truncated, info = env.step(action)\n",
        "        end = done | truncated\n",
        "    rewards.append(reward)\n",
        "\n",
        "print('Recompensa promedio:', np.mean(rewards))\n",
        "print('Desviaci칩n est치ndar de recompensas:', np.std(rewards))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOcLZzp3r_nT"
      },
      "source": [
        "La recompensa promedio es mayor y m치s cercana a 0 y hay m치s dispersi칩n en estas. Luego, se observa que el agente est치 actuando con m치s racionalidad, y tiene mejor performance que el azar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-EsAaPAYEm"
      },
      "source": [
        "#### **1.1.5 Estudio de acciones (0.2 puntos)**\n",
        "\n",
        "Genere una funci칩n que reciba un estado y retorne la accion del agente. Luego, use esta funci칩n para entregar la acci칩n escogida frente a los siguientes escenarios:\n",
        "\n",
        "- Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
        "- Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
        "\n",
        "쯉on coherentes sus acciones con las reglas del juego?\n",
        "\n",
        "Hint: 쮸 que clase de python pertenecen los estados? Pruebe a usar el m칠todo `.reset` para saberlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYPy2kxHqZG9",
        "outputId": "250c3dea-a66a-49a4-8c8a-462fa524d628"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([21,  2,  1])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state, info = env.reset()\n",
        "state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P_zcektqxEI"
      },
      "source": [
        "Los estados son de clase `np.array`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh8XlGyzwtRp",
        "outputId": "7517ff75-74ea-4e3d-f72d-5b79d5f62f9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estado: Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\n",
            "Acci칩n: Hit\n",
            "Estado: Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\n",
            "Acci칩n: Stick\n"
          ]
        }
      ],
      "source": [
        "def get_action(state):\n",
        "    action, _states = model.predict(state, deterministic=True)\n",
        "    action = action.item()\n",
        "\n",
        "    if action == 1:\n",
        "        return 'Hit'\n",
        "    else:\n",
        "        return 'Stick'\n",
        "\n",
        "# Definici칩n de estados\n",
        "s1 = np.array([6, 7, 0])\n",
        "s2 = np.array([19, 3, 1])\n",
        "\n",
        "print(\"Estado: Suma de cartas del agente es 6, dealer muestra un 7, agente no tiene tiene un as\\nAcci칩n:\", get_action(s1))\n",
        "print(\"Estado: Suma de cartas del agente es 19, dealer muestra un 3, agente tiene tiene un as\\nAcci칩n:\", get_action(s2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT-jE172rs7N"
      },
      "source": [
        "Las acciones tienen sentido. En el primer estado, el agente tiene una suma de 6 y sin as, est치 lejos de 21 y es mejor realizar un \"hit\" para pedir otra carta. En el segundo caso, tiene una suma de 19 y un as, est치 muy cerca de 21. No tiene sentido pedir otra carta, por lo que decide un \"stick\" para quedarse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqCTqqroh03"
      },
      "source": [
        "### **1.2 LunarLander**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://i.redd.it/097t6tk29zf51.jpg\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci칩n 2.1, en esta secci칩n usted se encargar치 de implementar una gente de RL que pueda resolver el ambiente `LunarLander`.\n",
        "\n",
        "Comencemos preparando el ambiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nvQUyuZ_FtZ4"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\"LunarLander-v3\", render_mode = \"rgb_array\", continuous = True) # notar el par치metro continuous = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBU4lGX3wpN6"
      },
      "source": [
        "Noten que se especifica el par치metro `continuous = True`. 쯈ue implicancias tiene esto sobre el ambiente?\n",
        "\n",
        "Adem치s, se le facilita la funci칩n `export_gif` para el ejercicio 2.2.4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bRiWpSo9yfr9"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "\n",
        "def export_gif(model, n = 5):\n",
        "  '''\n",
        "  funci칩n que exporta a gif el comportamiento del agente en n episodios\n",
        "  '''\n",
        "  images = []\n",
        "  for episode in range(n):\n",
        "    obs = model.env.reset()\n",
        "    img = model.env.render()\n",
        "    done = False\n",
        "    while not done:\n",
        "      images.append(img)\n",
        "      action, _ = model.predict(obs)\n",
        "      obs, reward, done, info = model.env.step(action)\n",
        "      img = model.env.render(mode=\"rgb_array\")\n",
        "\n",
        "  imageio.mimsave(\"agent_performance.gif\", [np.array(img) for i, img in enumerate(images) if i%2 == 0], fps=29)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk5VJVppXh3N"
      },
      "source": [
        "#### **1.2.1 Descripci칩n de MDP (0.2 puntos)**\n",
        "\n",
        "Entregue una breve descripci칩n sobre el ambiente [LunarLander](https://gymnasium.farama.org/environments/box2d/lunar_lander/) y su formulaci칩n en MDP, distinguiendo de forma clara y concisa los estados, acciones y recompensas. 쮺omo se distinguen las acciones de este ambiente en comparaci칩n a `Blackjack`?\n",
        "\n",
        "Nota: recuerde que se especific칩 el par치metro `continuous = True`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb-u9LUE8O9a"
      },
      "source": [
        "El ambiente `Lunar Lander` contiene un problema de optimizaci칩n de la trayectoria de un cohete en 2D, con el objetivo de aterrizar en una plataforma en la posici칩n (0,0), planteado como un problema de RL.\n",
        "\n",
        "En cada episodio, el cohete debe decidir una secuencia de movimientos de motor y propulsores (encenderlos o apagarlos) para aterrizar correctamente. El episodio termina si:\n",
        "\n",
        "- El cohete choca (su cuerpo entra en contacto con la superficie).\n",
        "- El cohete sale de la vista (coordenada $x$ con magnitud mayor a 1).\n",
        "- El cohete est치 en reposo.\n",
        "\n",
        "Su formulaci칩n en MDP consiste de los siguientes componentes (tomando en consideraci칩n el uso del par치metro `continuous=True`:\n",
        "\n",
        "- Estados: Cada observaci칩n corresponde a un vector de 8 dimensiones, con las coordenadas de la posici칩n del cohete ($x$ e $y$ ambos con valores entre -2.5 y +2.5), sus velocidades lineales en $x$ e $y$ (ambas de -10 a +10), su 치ngulo de inclinaci칩n (de $-2\\pi$ a $+2\\pi$), su velocidad angular (de -10 a +10) y dos valores `booleans` que representan si cada \"pata\" del cohete est치n en contacto con la superficie o no.\n",
        "\n",
        "- Acciones: A diferencia del ambiente de `blackjack`, el espacio de acci칩n es continuo, conformado por dos coordenadas (`main`, `lateral`) que pueden tomar valores de -1 a +1. La primera coordenada `main` indica la aceleraci칩n del motor principal del cohete, est치ndo completamente apagado cuando `main < 0` y escala de forma lineal entre 50% y 100% cuando `0 <= main <= 1`. De manera similar, la coordenada `lateral` indica la aceleraci칩n de los propulsores laterales, donde estar치n ambos apagados si `-0.5 < lateral < 0.5` y escalar치 la propulsi칩n linealmente entre 50% y 100% si `-1 <= lateral <= -0.5` (o `0.5 <= lateral <= 1`) para el propulsor izquierdo (o derecho, respectivamente).\n",
        "\n",
        "- Recompensas: A diferencia del ambiente de `blackjack` (donde la recompensa se obtiene s칩lo al terminar el juego) hay una recompensa despu칠s de cada paso, obteniendose una recompensa total del espisodio como la suma de las obtenidas en cada paso de este.\n",
        "\n",
        "    Para cada paso, la recompensa:\n",
        "\n",
        "    - Aumenta/disminuye seg칰n lo cerca/lejos se encuentre el cohete de la plataforma de aterrizaje.\n",
        "    - Aumenta/disminuye seg칰n lo lento/r치pido se mueva el cohete.\n",
        "    - Disminuye mientras m치s inclinado est칠 el cohete.\n",
        "    - Aumenta en 10 puntos por cada \"pata\" en contacto con la superficie.\n",
        "    - Disminuye en 0.03 puntos por cada \"cuadro\" de la trayectoria donde un propulsor est칠 encendido.\n",
        "    - Disminuye en 0.3 puntos por cada \"cuadro\" de la trayectoria donde el motor principal est칠 encendido.\n",
        "\n",
        "    Un episodio recibe una recompensa adicional en los siguientes casos:\n",
        "\n",
        "    - Aumenta 100 puntos si aterriza de forma segura.\n",
        "    - Disminuye 100 puntos si choca.\n",
        "\n",
        "    Finalmente, un episodio se considera una soluci칩n v치lida si logra al menos 100 puntos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YChodtNQwzG2"
      },
      "source": [
        "#### **1.2.2 Generando un Baseline (0.2 puntos)**\n",
        "\n",
        "Simule un escenario en donde se escojan acciones aleatorias. Repita esta simulaci칩n 10 veces y reporte el promedio y desviaci칩n de las recompensas. 쮺칩mo calificar칤a el performance de esta pol칤tica?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bwc3A0GX7a8",
        "outputId": "f6dbc949-9ebf-47cc-8c10-6446ef622de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recompensa promedio: -100.0\n",
            "Desviaci칩n est치ndar de recompensas: 0.0\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "n_simulations = 10\n",
        "rewards = []\n",
        "\n",
        "for episode in range(n_simulations):\n",
        "    env.reset(seed=random.randint(1, 10000))\n",
        "    end = False\n",
        "\n",
        "    while not end:\n",
        "        main = random.uniform(-1, 1)\n",
        "        lateral = random.uniform(-1, 1)\n",
        "        state, reward, done, truncated, info = env.step([main, lateral])\n",
        "        end = done | truncated\n",
        "    rewards.append(reward)\n",
        "\n",
        "print('Recompensa promedio:', np.mean(rewards))\n",
        "print('Desviaci칩n est치ndar de recompensas:', np.std(rewards))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMM1JixLuePW"
      },
      "source": [
        "La performance de esta pol칤tica es mala, en promedio la recompensa es de -100, lo que indica que el cohete siempre choca."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQrZVQflX_5f"
      },
      "source": [
        "#### **1.2.3 Entrenamiento de modelo (0.2 puntos)**\n",
        "\n",
        "A partir del siguiente [enlace](https://stable-baselines3.readthedocs.io/en/master/guide/algos.html), escoja un modelo de `stable_baselines3` y entrenelo para resolver el ambiente `LunarLander` **usando 10000 timesteps de entrenamiento**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "5a115967f34d4dcebbf328cc16ecb845",
            "0678c1f060f54ad289eeb8cc079a4739"
          ]
        },
        "id": "y_6Ia9uoF7Hs",
        "outputId": "f5def390-a066-4a3c-d92a-57e6867a314e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "223c260c3cd645adb819881228809b19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7fe38db52610>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "# init agent\n",
        "model = PPO(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# train the agent and display a progress bar\n",
        "model.learn(total_timesteps=10000, progress_bar=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z-oIUSrlAsY"
      },
      "source": [
        "#### **1.2.4 Evaluaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita el ejercicio 1.2.2 pero utilizando el modelo entrenado. 쮺칩mo es el performance de su agente? 쮼s mejor o peor que el escenario baseline?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ophyU3KrWrwl",
        "outputId": "b70ccaf4-2ec5-472c-b199-d1d0577615db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recompensa promedio: -100.0\n",
            "Desviaci칩n est치ndar de recompensas: 0.0\n"
          ]
        }
      ],
      "source": [
        "n_simulations = 10\n",
        "rewards = []\n",
        "\n",
        "for episode in range(n_simulations):\n",
        "    end = False\n",
        "    result = None\n",
        "    state, info = env.reset(seed=random.randint(1, 10000))\n",
        "\n",
        "    while not end:\n",
        "        action, _states = model.predict(state, deterministic=True)\n",
        "        state, reward, done, truncated, info = env.step(action)\n",
        "        end = done | truncated\n",
        "    rewards.append(reward)\n",
        "\n",
        "print('Recompensa promedio:', np.mean(rewards))\n",
        "print('Desviaci칩n est치ndar de recompensas:', np.std(rewards))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La performance sigue siendo igual de mala que el caso baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6Xw4YHT3P5d"
      },
      "source": [
        "#### **1.2.5 Optimizaci칩n de modelo (0.2 puntos)**\n",
        "\n",
        "Repita los ejercicios 1.2.3 y 1.2.4 hasta obtener un nivel de recompensas promedio mayor a 50. Para esto, puede cambiar manualmente par치metros como:\n",
        "- `total_timesteps`\n",
        "- `learning_rate`\n",
        "- `batch_size`\n",
        "\n",
        "Una vez optimizado el modelo, use la funci칩n `export_gif` para estudiar el comportamiento de su agente en la resoluci칩n del ambiente y comente sobre sus resultados.\n",
        "\n",
        "Adjunte el gif generado en su entrega (mejor a칰n si adem치s adjuntan el gif en el markdown)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51,
          "referenced_widgets": [
            "be65422cf0be4c90bab935bc012c609d",
            "cabdbad743c54b05bdbe6e0606611f8f"
          ]
        },
        "id": "aItYF6sr6F_6",
        "outputId": "6d9c3744-496b-4251-c318-ab98056ef31a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4ead3e986964cfeb28e265bb532c6eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7fe2af1f3250>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2 = PPO(\"MlpPolicy\", env, verbose=0)\n",
        "\n",
        "# train the agent and display a progress bar\n",
        "model2.learn(total_timesteps=200000, progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2A78xHk1zBP",
        "outputId": "9e85198f-2d92-4543-a70d-07ac8cb3f917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recompensa promedio: 80.0\n",
            "Desviaci칩n est치ndar de recompensas: 60.0\n"
          ]
        }
      ],
      "source": [
        "n_simulations = 10\n",
        "rewards = []\n",
        "\n",
        "for episode in range(n_simulations):\n",
        "    end = False\n",
        "    result = None\n",
        "    state, info = env.reset(seed=random.randint(1, 10000))\n",
        "\n",
        "    while not end:\n",
        "        action, _states = model2.predict(state, deterministic=True)\n",
        "        state, reward, done, truncated, info = env.step(action)\n",
        "        end = done | truncated\n",
        "    rewards.append(reward)\n",
        "\n",
        "print('Recompensa promedio:', np.mean(rewards))\n",
        "print('Desviaci칩n est치ndar de recompensas:', np.std(rewards))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xfSltZ92JG3",
        "outputId": "41425d0e-dca9-468a-bdd8-3c7b0365a629"
      },
      "outputs": [],
      "source": [
        "export_gif(model2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al entrenar con 200000 timesteps el agente obtiene una recompensa promedio de 80. A continuaci칩n se puede visualizar el gif generado, donde se aprecia que el agente aterriza de forma cuidadosa, casi dentro de la plataforma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYgiiowa2K9M"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"agent_performance.gif\"\n",
        "\" width=\"400\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPUY-Ktgf2BO"
      },
      "source": [
        "## **2. Large Language Models (4.0 puntos)**\n",
        "\n",
        "En esta secci칩n se enfocar치n en habilitar un Chatbot que nos permita responder preguntas 칰tiles a trav칠s de LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ4fPRRihGLe"
      },
      "source": [
        "### **2.0 Configuraci칩n Inicial**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/uqAs9atZH58AAAAd/config-config-issue.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Como siempre, cargamos todas nuestras API KEY al entorno:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ud2Xm_k-hFJn"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
        "\n",
        "if \"TAVILY_API_KEY\" not in os.environ:\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj9JvQUsgZZJ"
      },
      "source": [
        "### **2.1 Retrieval Augmented Generation (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://y.yarn.co/218aaa02-c47e-4ec9-b1c9-07792a06a88f_text.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsecci칩n es que habiliten un chatbot que pueda responder preguntas usando informaci칩n contenida en documentos PDF a trav칠s de **Retrieval Augmented Generation.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxOQroVnaZ5"
      },
      "source": [
        "#### **2.1.1 Reunir Documentos (0 puntos)**\n",
        "\n",
        "Reuna documentos PDF sobre los que hacer preguntas siguiendo las siguientes instrucciones:\n",
        "  - 2 documentos .pdf como m칤nimo.\n",
        "  - 50 p치ginas de contenido como m칤nimo entre todos los documentos.\n",
        "  - Ideas para documentos: Documentos relacionados a temas acad칠micos, laborales o de ocio. Aprovechen este ejercicio para construir algo 칰til y/o relevante para ustedes!\n",
        "  - Deben ocupar documentos reales, no pueden utilizar los mismos de la clase.\n",
        "  - Deben registrar sus documentos en la siguiente [planilla](https://docs.google.com/spreadsheets/d/1Hy1w_dOiG2UCHJ8muyxhdKPZEPrrL7BNHm6E90imIIM/edit?usp=sharing). **NO PUEDEN USAR LOS MISMOS DOCUMENTOS QUE OTRO GRUPO**\n",
        "  - **Recuerden adjuntar los documentos en su entrega**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D1tIRCi4oJJ",
        "outputId": "d2c7439a-bf97-4ad1-e453-2aaf3c3600d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kzq2TjWCnu15"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "doc_paths = [\"coli_a_00524.pdf\", \"2409.16430v1.pdf\"] # rellenar con los path a sus documentos\n",
        "\n",
        "assert len(doc_paths) >= 2, \"Deben adjuntar un m칤nimo de 2 documentos\"\n",
        "\n",
        "total_paginas = sum(len(PyPDF2.PdfReader(open(doc, \"rb\")).pages) for doc in doc_paths)\n",
        "assert total_paginas >= 50, f\"P치ginas insuficientes: {total_paginas}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r811-P71nizA"
      },
      "source": [
        "#### **2.1.2 Vectorizar Documentos (0.2 puntos)**\n",
        "\n",
        "Vectorice los documentos y almacene sus representaciones de manera acorde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vth3TGUUzj-p",
        "outputId": "6875fb48-f8b1-49fc-a916-e07f9d51be47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet langchain-google-genai faiss-cpu langchain_community pypdf wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "n-yXAdCSn4JM"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "def generate_vectorstore(doc_paths=doc_paths, chunk_size=500, chunk_overlap=50):\n",
        "    docs = list()\n",
        "\n",
        "    # Load\n",
        "    for doc in doc_paths:\n",
        "        loader = PyPDFLoader(doc)\n",
        "\n",
        "        docs += loader.load()\n",
        "\n",
        "    # Split\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap) # inicializamos splitter\n",
        "    splits = text_splitter.split_documents(docs) # dividir documentos en chunks\n",
        "\n",
        "    # Embed & Store\n",
        "    embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\") # inicializamos los embeddings\n",
        "    vectorstore = FAISS.from_documents(documents=splits, embedding=embedding) # vectorizacion y almacenamiento\n",
        "    return vectorstore\n",
        "\n",
        "base_vectorstore = generate_vectorstore()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAUkP5zrnyBK"
      },
      "source": [
        "#### **2.1.3 Habilitar RAG (0.3 puntos)**\n",
        "\n",
        "Habilite la soluci칩n RAG a trav칠s de una *chain* y gu치rdela en una variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "gPIySdDFn99l"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# LLM\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\", # modelo de lenguaje\n",
        "    temperature=0, # probabilidad de \"respuestas creativas\"\n",
        "    max_tokens=None, # sin tope de tokens\n",
        "    timeout=None, # sin timeout\n",
        "    max_retries=2, # n칰mero m치ximo de intentos\n",
        ")\n",
        "\n",
        "# Funci칩n auxiliar para formatear respuesta\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "def generate_rag_chain(vectorstore=base_vectorstore, k=3, search_type=\"similarity\"):\n",
        "    # Retriever chain\n",
        "    retriever = vectorstore.as_retriever(search_type=search_type, # m칠todo de b칰squeda\n",
        "                                        search_kwargs={\"k\": k}, # n춿 documentos a recuperar\n",
        "                                        )\n",
        "    retriever_chain = retriever | format_docs # chain\n",
        "\n",
        "    # RAG chain\n",
        "    llm_bias_rag_template = '''\n",
        "    You are an expert assistant specializing in biases in large language models (LLMs).\n",
        "    Your sole role is to answer user questions strictly based on the relevant information provided to you.\n",
        "    Always provide the most comprehensive and precise response possible, using only the supplied context.\n",
        "    Answer only what is asked; NEVER fabricate or infer details beyond the given information.\n",
        "\n",
        "    Relevant information: {context}\n",
        "    Question: {question}\n",
        "    Answer:\n",
        "    '''\n",
        "\n",
        "    rag_prompt = PromptTemplate.from_template(llm_bias_rag_template)\n",
        "\n",
        "    rag_chain = (\n",
        "        {\n",
        "            \"context\": retriever_chain, # context lo obtendremos del retriever_chain\n",
        "            \"question\": RunnablePassthrough(), # question pasar치 directo hacia el prompt\n",
        "        }\n",
        "        | rag_prompt # prompt con las variables question y context\n",
        "        | llm # llm recibe el prompt y responde\n",
        "        | StrOutputParser() # recuperamos s칩lo la respuesta\n",
        "    )\n",
        "\n",
        "    return rag_chain\n",
        "\n",
        "base_rag_chain = generate_rag_chain()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycg5S5i_n-kL"
      },
      "source": [
        "#### **2.1.4 Verificaci칩n de respuestas (0.5 puntos)**\n",
        "\n",
        "Genere un listado de 3 tuplas (\"pregunta\", \"respuesta correcta\") y analice la respuesta de su soluci칩n para cada una. 쯉u soluci칩n RAG entrega las respuestas que esperaba?\n",
        "\n",
        "Ejemplo de tupla:\n",
        "- Pregunta: 쯈ui칠n es el presidente de Chile?\n",
        "- Respuesta correcta: El presidente de Chile es Gabriel Boric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR-efkaY5ll9"
      },
      "source": [
        "Se definen las siguientes tuplas:\n",
        "- Tupla 1:\n",
        "    - Pregunta: What are social biases?\n",
        "    - Respuesta correcta: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
        "- Tupla 2:\n",
        "    - Pregunta: Which word embedding-based metrics exist for measuring bias in LLMs?\n",
        "    - Respuesta correcta: Word Embedding metrics and Sentence Embedding metrics\n",
        "- Tupla 3:\n",
        "    - Pregunta: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
        "    - Respuesta correcta: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDfYt2UC6GUN",
        "outputId": "c16a18cf-5e35-470e-da91-8dc5798be241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Social biases are defined as disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries. Within the LLM system, social bias reflects societal prejudices and stereotypes present in training data.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: The provided information describes what embedding-based metrics are and what they use, but it does not list specific names of embedding-based metrics that exist for measuring bias in LLMs. It mentions \"Word Embedding Metrics\" as a category and states that one relevant method for static word embeddings is presented, but does not name it.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: The types of techniques for bias mitigation in LLMs that intervene in the pre-processing stage are:\n",
            "*   Data Augmentation\n",
            "*   Data Filtering & Reweighting\n",
            "*   Data Generation\n",
            "*   Instruction Tuning\n",
            "\n"
          ]
        }
      ],
      "source": [
        "questions = [\n",
        "    (\"What are social biases?\", \"Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\"),\n",
        "    (\"Which embedding-based metrics exists for measuring bias in LLMs?\", \"Word Embedding metrics and Sentence Embedding metrics\"),\n",
        "    (\"What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\", \"Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\")\n",
        "]\n",
        "\n",
        "def ask_questions(chain=base_rag_chain):\n",
        "    for q in questions:\n",
        "        print(\"Question: \" + q[0] + '\\nExpected Answer: ' + q[1] + '\\nAnswer: ' + chain.invoke(q[0]) + \"\\n\")\n",
        "\n",
        "ask_questions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El RAG entrega una buena respuesta para las preguntas 1 y la 3, pero la tupla 2 es menos precisa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8d5zTMHoUgF"
      },
      "source": [
        "#### **2.1.5 Sensibilidad de Hiperpar치metros (0.5 puntos)**\n",
        "\n",
        "Extienda el an치lisis del punto 2.1.4 analizando c칩mo cambian las respuestas entregadas cambiando los siguientes hiperpar치metros:\n",
        "- `Tama침o del chunk`. (*쮺칩mo repercute que los chunks sean mas grandes o chicos?*)\n",
        "- `La cantidad de chunks recuperados`. (*쯈u칠 pasa si se devuelven muchos/pocos chunks?*)\n",
        "- `El tipo de b칰squeda`. (*쮺칩mo afecta el tipo de b칰squeda a las respuestas de mi RAG?*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDh_QgeXLGHc",
        "outputId": "a1c76835-e33d-4e81-b948-bc6a29216c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Based on the provided information, social bias is described as \"a subjective and\" (the description is incomplete in the provided text). Racial bias is also stated to be a form of social bias.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: The provided information states that \"Bias in the embedding space can have a\" in the context of metrics for assessing bias in LLMs. However, it does not list any specific embedding-based metrics.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: Based on the provided information, there is no mention of bias mitigation techniques that intervene in the pre-processing stage. The text only refers to \"post-processing bias mitigations\" and general \"bias mitigations apply to an LLM\".\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambio de tama침o de chunk\n",
        "vectorstore_small_chunk = generate_vectorstore(chunk_size=50)\n",
        "rag_chain_small_chunk = generate_rag_chain(vectorstore=vectorstore_small_chunk)\n",
        "ask_questions(chain=rag_chain_small_chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Based on the provided information, \"social bias\" is referred to as \"bias\" unless otherwise specified, and its definition is stated to be in \"Definition 7.\" However, \"Definition 7\" is not included in the provided text. Therefore, the specific definition of social bias is not available in the given context.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: Embedding-based metrics for measuring bias in LLMs include Word Embedding Metrics. These metrics typically compute distances in the vector space between neutral words (e.g., professions) and identity-related words (e.g., gender pronouns). While first proposed for static word embeddings, their basic formulation of computing cosine distances between neutral and gendered words has been generalized to contextualized embeddings used in LLMs.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: The types of techniques for bias mitigation in LLMs that intervene in the pre-processing stage are:\n",
            "\n",
            "*   Data Augmentation\n",
            "*   Data Filtering & Reweighting\n",
            "*   Data Generation\n",
            "*   Instruction Tuning\n",
            "*   Projection-based Mitigation\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambio de tama침o de chunk\n",
        "vectorstore_big_chunk = generate_vectorstore(chunk_size=1000)\n",
        "rag_chain_big_chunk = generate_rag_chain(vectorstore=vectorstore_big_chunk)\n",
        "ask_questions(chain=rag_chain_big_chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al utilizar chunks m치s peque침os, el texto parece ser insuficiente para responder preguntas complejas que antes si pod칤a resolver, como la tupla 3. Por otro lado, al usar chunks m치s grandes el texto proporcionado es de mayor tama침o, y algunas respuestas son m치s complejas, como la de la tupla 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Social biases are defined as disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: Based on the provided information, the text defines embedding-based metrics as those that use dense vector representations, typically contextual sentence embeddings, to measure bias. However, it does not list or name any specific embedding-based metrics.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: The types of techniques that exist for Bias Mitigation in LLMs that intervene in the pre-processing stage are:\n",
            "*   Data Augmentation\n",
            "*   Data Filtering & Reweighting\n",
            "*   Data Generation\n",
            "*   Instruction Tuning\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambio de cantidad de chunk recuperados\n",
        "rag_chain_less_chunks = generate_rag_chain(k=1)\n",
        "ask_questions(chain=rag_chain_less_chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSPOgSsB7g2A",
        "outputId": "4f20ac62-087a-4a0d-813a-ac38d4d52c29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Social bias broadly encompasses disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries. It is a subjective and normative term used to refer to harms such as stereotypes, misrepresentations, derogatory and exclusionary language, and other denigrating behaviors that disproportionately affect already-vulnerable and marginalized communities.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: Based on the provided information, the text describes how embedding-based metrics work (e.g., computing distances in vector space between neutral words and identity-related words, or using cosine similarity to compare words like \"doctor\" to social group terms like \"man\"), but it does not list specific names of embedding-based metrics for measuring bias in LLMs.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: Bias mitigation techniques that intervene in the pre-processing stage include:\n",
            "\n",
            "*   **Data Augmentation** (춶 5.1.1): This involves extending the distribution with new data.\n",
            "*   **Data Filtering & Reweighting** (춶 5.1.2): This technique focuses on removing or reweighting instances.\n",
            "*   **Data Generation** (춶 5.1.3): This involves producing new data that meets certain standards.\n",
            "*   **Instruction Tuning** (춶 5.1.4): This technique involves prepending additional instructions or triggers to a prompt to generate an unbiased output.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambio de cantidad de chunk recuperados\n",
        "rag_chain_more_chunks = generate_rag_chain(k=20)\n",
        "ask_questions(chain=rag_chain_more_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Al recuperar pocos chunks (y por ello, menos texto), las respuestas son m치s dificiles de responder, como en la pregunta 2, donde se indica que el texto es insuficiente. Mientras que muchos chunks de texto aportan m치s informaci칩n encontrada, permitiendo construir respuestas m치s complejas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTCvwIaz8qiT",
        "outputId": "5e82a54a-3837-41d4-9f9a-2d0496ca16ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are social biases?\n",
            "Expected Answer: Social biases are disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries\n",
            "Answer: Social bias refers to disparate treatment or outcomes between social groups that arise from historical and structural power asymmetries.\n",
            "\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs?\n",
            "Expected Answer: Word Embedding metrics and Sentence Embedding metrics\n",
            "Answer: Based on the provided information, the text defines embedding-based metrics as those that use dense vector representations, typically contextual sentence embeddings, to measure bias. However, it does not list any specific named embedding-based metrics for measuring bias in LLMs. The \"EMBEDDINGS\" section in Table 6 refers to objective functions for bias *mitigation* by modifying embeddings, not metrics for measuring bias.\n",
            "\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage?\n",
            "Expected Answer: Data Augmentation, Data Filtering & Reweighting, Data Generation, Instruction Tuning and Projection-based Mitigation\n",
            "Answer: The types of techniques that exist for Bias Mitigation in LLMs that intervene in the pre-processing stage are:\n",
            "*   Data Augmentation\n",
            "*   Data Filtering & Reweighting\n",
            "*   Data Generation\n",
            "*   Instruction Tuning\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cambio de tipo de busqueda\n",
        "rag_chain_other_search = generate_rag_chain(search_type=\"mmr\")\n",
        "ask_questions(chain=rag_chain_other_search)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finalmente, al cambiar la funci칩n de b칰squeda la tupla 2 incorpora informaci칩n m치s informaci칩n, pero sin lograr responder correctamente, mientras que la tupla 1 entrega una respuesta casi perfecta y la 3 se mantiene constante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENJiPPM0giX8"
      },
      "source": [
        "### **2.2 Agentes (1.0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/rcqnN2aJCSEAAAAd/secret-agent-man.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Similar a la secci칩n anterior, en esta secci칩n se busca habilitar **Agentes** para obtener informaci칩n a trav칠s de tools y as칤 responder la pregunta del usuario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V47l7Mjfrk0N"
      },
      "source": [
        "#### **2.2.1 Tool de Tavily (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas al motor de b칰squeda **Tavily**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "R6SLKwcWr0AG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_31006/4138654522.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tavily_search = TavilySearchResults(max_results = 1)\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tavily_search = TavilySearchResults(max_results = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SonB1A-9rtRq"
      },
      "source": [
        "#### **2.2.2 Tool de Wikipedia (0.2 puntos)**\n",
        "\n",
        "Generar una *tool* que pueda hacer consultas a **Wikipedia**.\n",
        "\n",
        "*Hint: Le puede ser de ayuda el siguiente [link](https://python.langchain.com/v0.1/docs/modules/tools/).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ehJJpoqsr26-"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
        "wikipedia_query = WikipediaQueryRun(api_wrapper=api_wrapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvUIMdX6r0ne"
      },
      "source": [
        "#### **2.2.3 Crear Agente (0.3 puntos)**\n",
        "\n",
        "Crear un agente que pueda responder preguntas preguntas usando las *tools* antes generadas. Aseg칰rese que su agente responda en espa침ol. Por 칰ltimo, guarde el agente en una variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "pD1_n0wrsDI5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/felipe/.pyenv/versions/lab11/lib/python3.11/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: capital de chile\u001b[0m\u001b[33;1m\u001b[1;3mPage: Santiago\n",
            "Summary: Santiago (, US also ; Spanish: [san틛tja톢o]), also known as Santiago de Chile\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: La capital de Chile es Santiago.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "La capital de Chile es Santiago.\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "\n",
        "tools = [tavily_search, wikipedia_query]\n",
        "react_prompt = hub.pull(\"hwchase17/react\")\n",
        "agent = create_react_agent(llm, tools, react_prompt) # primero inicializamos el agente ReAct\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True) # lo transformamos a AgentExecutor para habilitar la ejecuci칩n de tools\n",
        "\n",
        "response = agent_executor.invoke({\"input\": \"Hola, cual es la capital de chile?\"})\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El agente responde en espa침ol si problemas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKV0JxK3r-XG"
      },
      "source": [
        "#### **2.2.4 Verificaci칩n de respuestas (0.3 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente y aseg칰rese que el agente est칠 ocupando correctamente las tools disponibles. 쮼n qu칠 casos el agente deber칤a ocupar la tool de Tavily? 쮼n qu칠 casos deber칤a ocupar la tool de Wikipedia?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El agente deber칤a usar la tool de Tavily cuando la pregunta es sobre poco precisa respecto al t칩pico, como al consultar \"C칩mo puedo cocinar un pollo?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "15NvwR7Z_9TR",
        "outputId": "7deb1143-7431-49f6-8454-1e23568f01af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: c칩mo cocinar un pollo\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Pollo en salsa. Receta tradicional y casera', 'url': 'https://recetasdecocina.elmundo.es/2024/10/pollo-en-salsa-receta-tradicional-y-casera.html', 'content': 'Hacer pollo en salsa ... 1.- Comenzamos salpimentando los trozos de pollo y dor치ndolos a fuego fuerte en una cocerlo. Una vez dorados, los', 'score': 0.523494}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: m칠todos para cocinar pollo\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'C칩mo cocinar las distintas partes del pollo - Recetas Nestl칠', 'url': 'https://www.recetasnestlecam.com/escuela-sabor/recetas/preparaciones-pollo', 'content': 'La mejor pechuga de pollo 췅 A la plancha: este m칠todo se suele usar con los filetes, aprovechando que son m치s delgados. 췅 En brochetas: aprovecha', 'score': 0.6342494}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: formas comunes de cocinar pollo\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Las 71 mejores recetas de pollo - Directo al Paladar', 'url': 'https://www.directoalpaladar.com/recetario/71-mejores-recetas-pollo', 'content': 'Pocos elementos nos han dado en la cocina tantos momentos de gloria como el pollo. No importa el formato, corte o tipo de receta, pues **siempre hay una receta de pollo para cada momento** o tipo de cocina.\\n\\nDa igual que hablemos de pollos asados o de pollo frito. Tambi칠n da igual que hablemos de alitas de pollo, de muslos de pollo o los no menos relevantes contramuslos de pollo. Sea la pieza que sea, el pollo tiene un camino com칰n: ser **bueno, bonito y barato**. [...] Tras una intensa criba, podemos asegurarte que estas son **nuestras mejores recetas de pollo,** que vas a encontrar ordenadas por tipo de preparaci칩n 닻a sea frito, asado, al horno, a la plancha, guisado, a la parrilla뷕 y por tipo de corte, para que tengas a mano esta peque침a biblia gastron칩mica con la que convertir el pollo en un placer irresistible.\\n\\nGuisos de pollo\\n--------------- [...] *   [Pollo al horno con patatas](https://www.directoalpaladar.com/recetas-de-carnes-y-aves/pollo-al-horno-patatas-chorizo-receta-facilisima-para-uno)\\n*   [Pollo asado en olla expr칠s](https://www.directoalpaladar.com/recetas-de-carnes-y-aves/como-hacer-pollo-asado-olla-expres-receta-rapida-limpia-pollo-encender-horno)\\n*   [Pollo al carb칩n](https://www.directoalpaladar.com/recetas-de-carnes-y-aves/receta-pollo-al-carbon-marinado-asado-perfecto-para-parrilla-grill)', 'score': 0.62358373}]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Hay muchas maneras de cocinar pollo, dependiendo de la parte del pollo y el resultado deseado. Algunas de las formas m치s comunes incluyen:\n",
            "\n",
            "*   **A la plancha:** Ideal para filetes de pechuga, ya que son delgados y se cocinan r치pidamente.\n",
            "*   **En brochetas:** Se pueden usar trozos de pollo en brochetas con verduras.\n",
            "*   **Frito:** Una opci칩n popular para alitas o trozos de pollo empanizados.\n",
            "*   **Asado/Al horno:** Se puede asar un pollo entero o partes de pollo en el horno, a menudo con patatas u otras verduras.\n",
            "*   **Guisado/En salsa:** Cocinar el pollo a fuego lento en una salsa, lo que lo hace muy tierno y sabroso.\n",
            "*   **A la parrilla/Al carb칩n:** Para un sabor ahumado, se puede cocinar el pollo en una parrilla.\n",
            "\n",
            "Para muchas de estas preparaciones, un paso inicial com칰n es salpimentar el pollo y dorarlo a fuego fuerte antes de continuar con la cocci칩n.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Hay muchas maneras de cocinar pollo, dependiendo de la parte del pollo y el resultado deseado. Algunas de las formas m치s comunes incluyen:\n",
            "\n",
            "*   **A la plancha:** Ideal para filetes de pechuga, ya que son delgados y se cocinan r치pidamente.\n",
            "*   **En brochetas:** Se pueden usar trozos de pollo en brochetas con verduras.\n",
            "*   **Frito:** Una opci칩n popular para alitas o trozos de pollo empanizados.\n",
            "*   **Asado/Al horno:** Se puede asar un pollo entero o partes de pollo en el horno, a menudo con patatas u otras verduras.\n",
            "*   **Guisado/En salsa:** Cocinar el pollo a fuego lento en una salsa, lo que lo hace muy tierno y sabroso.\n",
            "*   **A la parrilla/Al carb칩n:** Para un sabor ahumado, se puede cocinar el pollo en una parrilla.\n",
            "\n",
            "Para muchas de estas preparaciones, un paso inicial com칰n es salpimentar el pollo y dorarlo a fuego fuerte antes de continuar con la cocci칩n.\n"
          ]
        }
      ],
      "source": [
        "response = agent_executor.invoke({\"input\": \"C칩mo puedo cocinar un pollo?\"})\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mientras que la tool de Wikipedia debe emplearse para responder preguntas sobre un t칩pico espec칤fico, como personas, lugares, eventos hist칩ricos, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: Lionel Messi\u001b[0m\u001b[33;1m\u001b[1;3mPage: Lionel Messi\n",
            "Summary: Lionel Andr칠s \"Leo\" Messi (Spanish pronunciation: [ljo틛nel an틛d쬰s 틛mesi\u001b[0m\u001b[32;1m\u001b[1;3mThought: The full summary from Wikipedia clearly states that Lionel Messi \"is an Argentine professional footballer\" and \"captains the Argentina national team.\" It also mentions he \"left his home country of Argentina\".\n",
            "Final Answer: Lionel Messi es de nacionalidad argentina.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Lionel Messi es de nacionalidad argentina.\n"
          ]
        }
      ],
      "source": [
        "response = agent_executor.invoke({\"input\": \"De qu칠 nacionalidad es Lionel Messi?\"})\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZbDTYiogquv"
      },
      "source": [
        "### **2.3 Multi Agente (1.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/r7QMJLxU4BoAAAAd/this-is-getting-out-of-hand-star-wars.gif\"\n",
        "\" width=\"450\">\n",
        "</p>\n",
        "\n",
        "El objetivo de esta subsecci칩n es encapsular las funcionalidades creadas en una soluci칩n multiagente con un **supervisor**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-iUfH0WvI6m"
      },
      "source": [
        "#### **2.3.1 Generando Tools (0.5 puntos)**\n",
        "\n",
        "Transforme la soluci칩n RAG de la secci칩n 2.1 y el agente de la secci칩n 2.2 a *tools* (una tool por cada uno)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "pw1cfTtvv1AZ"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def search_bias_query(query: str) -> str:\n",
        "    \"\"\"Asks a query to an expert about Biases in LLMs.\"\"\"\n",
        "    return base_rag_chain.invoke(query)\n",
        "\n",
        "@tool\n",
        "def search_general_query(query: str) -> str:\n",
        "    \"\"\"Asks a query about a general topic.\"\"\"\n",
        "    return agent_executor.invoke({\"input\": query})[\"output\"]\n",
        "\n",
        "multiagent_tools = [search_bias_query, search_general_query]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQYNjT_0vPCg"
      },
      "source": [
        "#### **2.3.2 Agente Supervisor (0.5 puntos)**\n",
        "\n",
        "Habilite un agente que tenga acceso a las tools del punto anterior y pueda responder preguntas relacionadas. Almacene este agente en una variable llamada supervisor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oqfx0WbMCfVG",
        "outputId": "097a27ba-17e7-44cf-d8b9-0134ea68d358"
      },
      "outputs": [],
      "source": [
        "supervisor_agent = create_react_agent(llm, multiagent_tools, react_prompt) # primero inicializamos el agente ReAct\n",
        "supervisor = AgentExecutor(agent=supervisor_agent, tools=multiagent_tools, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea3zWlvyvY7K"
      },
      "source": [
        "#### **2.3.3 Verificaci칩n de respuestas (0.25 puntos)**\n",
        "\n",
        "Pruebe el funcionamiento de su agente repitiendo las preguntas realizadas en las secciones 2.1.4 y 2.2.4 y comente sus resultados. 쮺칩mo var칤an las respuestas bajo este enfoque?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6_1t0zkgv1qW",
        "outputId": "7feca4e0-e716-4020-e46c-3518e2ac4385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: search_general_query\n",
            "Action Input: What are social biases?\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: social biases\u001b[0m\u001b[33;1m\u001b[1;3mPage: List of cognitive biases\n",
            "Summary: Cognitive biases are systematic patterns of deviation from n\u001b[0m\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: social bias\u001b[0m\u001b[33;1m\u001b[1;3mPage: Social-desirability bias\n",
            "Summary: In social science research social-desirability bias is a typ\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: what are social biases definition\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Social Biases | Free Essay Example for Students - Aithor', 'url': 'https://aithor.com/essay-examples/social-biases', 'content': 'A social bias is a process in which social groups can be categorized, often in a stereotypical way, and are treated differently and in an unfair manner as a result. There are many forms of social bias, including the most well-known form, which is prejudice. Prejudice is an unjust and usually negative attitude towards a group and its individual members. It often involves labeling, and this can be the starting point for more extreme forms of social bias. Discrimination is the action that [...] themselves as belonging. Social biases tend to have a self-perpetuating quality, in that the person who holds a biased belief about a certain group will likely behave in a way that is consistent with that belief, thereby appearing to confirm it in the eyes of themselves and others. Such behavior can also lead the person to interpret ambiguous actions by a member of the group in a way that is consistent with their biases. In these ways, social biases can lead to the overgeneralization of certain [...] Social biases arise when people have unconscious beliefs about various social groups, which influence behavior toward members of those groups. Because many of these beliefs are largely inaccurate and/or negative, social biases can result in unfair discrimination against certain groups. Common examples of social biases are those specifically associated with age, sex, race, and criminality, though people can be biased based on any assumed characteristic of a group to which they do not see', 'score': 0.8978479}]\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Social biases are processes where social groups are categorized, often stereotypically, leading to unfair and differential treatment. These biases often stem from unconscious beliefs about various social groups, which can influence behavior and result in unfair discrimination. Prejudice and discrimination are common forms of social bias.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mSocial biases are processes where social groups are categorized, often stereotypically, leading to unfair and differential treatment. These biases often stem from unconscious beliefs about various social groups, which can influence behavior and result in unfair discrimination. Prejudice and discrimination are common forms of social bias.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Social biases are processes that involve categorizing social groups, often through stereotypes, which can lead to unfair and differential treatment. They frequently originate from unconscious beliefs about various social groups, influencing behavior and resulting in unfair discrimination. Prejudice and discrimination are common manifestations of social bias.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Question: What are social biases? \n",
            "Answer: Social biases are processes that involve categorizing social groups, often through stereotypes, which can lead to unfair and differential treatment. They frequently originate from unconscious beliefs about various social groups, influencing behavior and resulting in unfair discrimination. Prejudice and discrimination are common manifestations of social bias.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: search_bias_query\n",
            "Action Input: embedding-based metrics for measuring bias in LLMs\u001b[0m\u001b[36;1m\u001b[1;3mEmbedding-based metrics for measuring bias in LLMs utilize the dense vector representations of the model, which are typically contextual sentence embeddings, to measure bias. These metrics leverage embeddings for bias evaluation.\u001b[0m\u001b[32;1m\u001b[1;3mAction: search_bias_query\n",
            "Action Input: specific embedding-based metrics for LLM bias\u001b[0m\u001b[36;1m\u001b[1;3mBased on the provided information, the text introduces \"Embedding-based metrics\" as a category for measuring bias using dense vector representations, typically contextual sentence embeddings. It states that a section (3.3) will discuss these metrics and mentions examples in Figures 35, but it does not provide the names of any specific embedding-based metrics.\u001b[0m\u001b[32;1m\u001b[1;3mAction: search_general_query\n",
            "Action Input: specific embedding-based metrics for measuring bias in LLMs\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: specific embedding-based metrics for measuring bias in LLMs\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias Detection in LLM Outputs: Statistical Approaches', 'url': 'https://machinelearningmastery.com/bias-detection-in-llm-outputs-statistical-approaches/', 'content': 'Embedding-based testing is a technique for identifying and measuring bias within the LLM embedding model, specifically in its latent', 'score': 0.85797083}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: embedding-based bias metrics LLMs\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias Detection in LLM Outputs: Statistical Approaches', 'url': 'https://machinelearningmastery.com/bias-detection-in-llm-outputs-statistical-approaches/', 'content': 'Embedding-based testing is a technique for identifying and measuring bias within the LLM embedding model, specifically in its latent representations. We know that an embedding is a high-dimension vector that encodes semantic relationships between words in the latent space. By examining the relationships, we can understand the biases from a model that came inherently from training data.', 'score': 0.882276}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: specific embedding bias metrics for LLMs\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias Detection in LLM Outputs: Statistical Approaches', 'url': 'https://machinelearningmastery.com/bias-detection-in-llm-outputs-statistical-approaches/', 'content': 'Embedding-based testing is a technique for identifying and measuring bias within the LLM embedding model, specifically in its latent representations. We know that an embedding is a high-dimension vector that encodes semantic relationships between words in the latent space. By examining the relationships, we can understand the biases from a model that came inherently from training data.', 'score': 0.77055156}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: named embedding-based bias metrics for LLMs\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias and Fairness in Large Language Models: A Survey - arXiv', 'url': 'https://arxiv.org/html/2309.00770v2', 'content': 'Table 3: Taxonomy of Evaluation Metrics for Bias Evaluation in LLMs. We summarize metrics that measure bias using embeddings, model-assigned probabilities, or generated text. The data structure describes the input to the model required to compute the metrics, and 洧洧륲\\\\\\\mathcal{D}caligraphic\\\\_D indicates if the metric was introduced with an accompanying dataset. W洧녥Witalic\\\\_W is the set of neutral words; Aisubscript洧냢洧녰A\\\\_{i}italic\\\\_A start\\\\_POSTSUBSCRIPT italic\\\\_i end\\\\_POSTSUBSCRIPT is the set of [...] Word Embedding222Static word embeddings are not used with LLMs, but we include the word embedding metric WEAT for completeness given its relevance to sentence embedding metrics. (춶[3.3.1](https://arxiv.org/html/2309.00770v2#S3.SS3.SSS1 \"3.3.1 Word Embedding Metrics  3.3 Embedding-Based Metrics  3 Taxonomy of Metrics for Bias Evaluation  Bias and Fairness in Large Language Models: A Survey\")): Compute distances in the embedding space\\n        \\n        Report issue for preceding element [...] Most bias evaluation metrics for LLMs can be categorized by _what_ they use from the model such as the _embeddings_, _probabilities_, or _generated text_. As such, we propose an intuitive taxonomy based on this categorization:\\n\\nReport issue for preceding element', 'score': 0.84183896}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: specific embedding-based bias metrics for large language models\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias in Large Language Models: Origin, Evaluation, and Mitigation', 'url': 'https://arxiv.org/html/2411.10915v1', 'content': 'Counterfactual Testing, Stereotype Detection, Sentiment and Toxicity Analysis, Acceptance and Rejection Rates, and Embedding-Based Metrics.', 'score': 0.77055156}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: WEAT for LLMs or sentence embedding bias metrics\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Bias and Fairness in Large Language Models: A Survey - arXiv', 'url': 'https://arxiv.org/html/2309.00770v2', 'content': 'Word Embedding222Static word embeddings are not used with LLMs, but we include the word embedding metric WEAT for completeness given its relevance to sentence embedding metrics. (춶[3.3.1](https://arxiv.org/html/2309.00770v2#S3.SS3.SSS1 \"3.3.1 Word Embedding Metrics  3.3 Embedding-Based Metrics  3 Taxonomy of Metrics for Bias Evaluation  Bias and Fairness in Large Language Models: A Survey\")): Compute distances in the embedding space\\n        \\n        Report issue for preceding element [...] Table 3: Taxonomy of Evaluation Metrics for Bias Evaluation in LLMs. We summarize metrics that measure bias using embeddings, model-assigned probabilities, or generated text. The data structure describes the input to the model required to compute the metrics, and 洧洧륲\\\\\\\mathcal{D}caligraphic\\\\_D indicates if the metric was introduced with an accompanying dataset. W洧녥Witalic\\\\_W is the set of neutral words; Aisubscript洧냢洧녰A\\\\_{i}italic\\\\_A start\\\\_POSTSUBSCRIPT italic\\\\_i end\\\\_POSTSUBSCRIPT is the set of [...] cd=\"ambiguous\" id=\"S3.T3.43.9.1.1.1.m1.2.2.4.3.1.cmml\" xref=\"S3.T3.43.9.1.1.1.m1.2.2.4.3\">subscript</csymbol><ci id=\"S3.T3.43.9.1.1.1.m1.2.2.4.3.2.cmml\" xref=\"S3.T3.43.9.1.1.1.m1.2.2.4.3.2\">洧녺</ci><ci id=\"S3.T3.43.9.1.1.1.m1.2.2.4.3.3.cmml\" xref=\"S3.T3.43.9.1.1.1.m1.2.2.4.3.3\">洧녰</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S3.T3.43.9.1.1.1.m1.4c\">f(S_{A},S_{W})=\\\\tfrac{\\\\Sigma_{i=1}^{N}v_{i}\\\\textrm{WEAT}(S_{A_{i}},S_{W_{i}})}%', 'score': 0.8286204}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: \"embedding-based bias metrics\" LLMs specific names\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'How to measure the Bias and Fairness of LLM?', 'url': 'https://substack.com/home/post/p-156509065?utm_campaign=post&utm_medium=web', 'content': 'Embedding-based metrics use embeddings to detect bias in LLMs. Specifically, these metrics compute distances in the embedding space between', 'score': 0.7520312}]\u001b[0m\u001b[32;1m\u001b[1;3mThought: I have searched for specific embedding-based metrics for measuring bias in LLMs. The results consistently point to the concept of \"embedding-based testing\" which involves examining relationships and computing distances in the latent space of embeddings. One specific metric mentioned is WEAT (Word Embedding Association Test), which is acknowledged for its relevance to sentence embedding metrics in LLMs, even though it originated for static word embeddings. The search results also mention that most bias evaluation metrics for LLMs can be categorized by what they use from the model (embeddings, probabilities, or generated text). While the general approach of \"computing distances in the embedding space\" is highlighted, WEAT is the most specific named metric found in the context of embedding-based bias measurement for LLMs. I will synthesize this information to answer the question.\n",
            "\n",
            "Final Answer: One specific embedding-based metric for measuring bias in LLMs is the **Word Embedding Association Test (WEAT)**. While originally developed for static word embeddings, it is considered relevant for sentence embedding metrics in the context of LLMs. Generally, embedding-based metrics for LLMs involve computing distances and examining relationships within the embedding space to identify and quantify biases present in the model's latent representations.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mOne specific embedding-based metric for measuring bias in LLMs is the **Word Embedding Association Test (WEAT)**. While originally developed for static word embeddings, it is considered relevant for sentence embedding metrics in the context of LLMs. Generally, embedding-based metrics for LLMs involve computing distances and examining relationships within the embedding space to identify and quantify biases present in the model's latent representations.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: One specific embedding-based metric for measuring bias in LLMs is the **Word Embedding Association Test (WEAT)**. These metrics generally involve computing distances and examining relationships within the embedding space to identify and quantify biases present in the model's latent representations.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Question: Which embedding-based metrics exists for measuring bias in LLMs? \n",
            "Answer: One specific embedding-based metric for measuring bias in LLMs is the **Word Embedding Association Test (WEAT)**. These metrics generally involve computing distances and examining relationships within the embedding space to identify and quantify biases present in the model's latent representations.\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: search_bias_query\n",
            "Action Input: Bias mitigation techniques LLMs pre-processing stage\u001b[0m\u001b[36;1m\u001b[1;3mBias mitigation techniques at the pre-processing stage in LLMs include:\n",
            "*   Data Augmentation\n",
            "*   Data Filtering & Reweighting\n",
            "*   Data Generation\n",
            "*   Instruction Tuning\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Techniques for bias mitigation in LLMs that intervene in the pre-processing stage include Data Augmentation, Data Filtering & Reweighting, Data Generation, and Instruction Tuning.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Question: What types of techniques exist for Bias Mitigation in LLMs that intervene in the pre-procesing stage? \n",
            "Answer: Techniques for bias mitigation in LLMs that intervene in the pre-processing stage include Data Augmentation, Data Filtering & Reweighting, Data Generation, and Instruction Tuning.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "for q in questions:\n",
        "    response = supervisor.invoke({\"input\": q[0]})\n",
        "    print(\"Question:\", q[0], \"\\nAnswer:\", response[\"output\"])\n",
        "    time.sleep(30)  # Para prevenir que se caiga por la cuota del free tier de Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: search_general_query\n",
            "Action Input: C칩mo cocinar un pollo\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: C칩mo cocinar un pollo\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Pollo - 74,888 recetas caseras- Cookpad', 'url': 'https://cookpad.com/eeuu/buscar/pollo', 'content': '*   \\n[Pollo en cazuela](https://cookpad.com/eeuu/recetas/17014457)\\n-------------------------------------------------------------  Guarda esta receta para encontrarla m치s f치cilmente cuando la quieras cocinar.   [](https://cookpad.com/eeuu/buscar/pollo# \"Cerrar\")          muslos de pollo  Sal  Pimienta  Ajo  Jugo de un lim칩n o naranja agria  Curry  Romero  Vino seco  Aceite vegetal  Pur칠 de tomate   \\n\\n    *   1h y 30 min\\n    *   3 o 4 raciones [...] ------------------------------------------------------------------------------------------------------------------------------------  Guarda esta receta para encontrarla m치s f치cilmente cuando la quieras cocinar.   [](https://cookpad.com/eeuu/buscar/pollo# \"Cerrar\")          muslos previamente hervidos con sal  huevos  ajos grandes  cebolla peque침a  ceboll칤n  Cilantro  especias: comino, paprika, or칠gano y especias italianas (las de tu preferencia)  Sal    ![Image 81: Eddy Moreno de [...] *   \\n[Pollo con verduras](https://cookpad.com/eeuu/recetas/16985032)\\n---------------------------------------------------------------  Guarda esta receta para encontrarla m치s f치cilmente cuando la quieras cocinar.   [](https://cookpad.com/eeuu/buscar/pollo# \"Cerrar\")          pechuga de pollo  Verduras de tu preferencia finamente picado  Sal  ajo  Pimienta  aceite  leche  laurel  agua   \\n\\n    *   40 minutos\\n    *   3 porciones', 'score': 0.65940565}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: C칩mo cocinar pollo m칠todos b치sicos\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Cl치sico pollo rostizado | Recetas - Cook for Your Life', 'url': 'https://www.cookforyourlife.org/es/recetas/clasico-pollo-rostizado/', 'content': 'Procedimiento 췅 Precalienta el horno a 400 grados. 췅 Retire cualquier paquete de menudencias del interior del pollo. 췅 Seque el pollo con una toalla de papel.', 'score': 0.48616135}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: M칠todos b치sicos para cocinar pollo\u001b[0m\u001b[36;1m\u001b[1;3m[{'title': 'Conoce m치s del pollo y crea deliciosos platos. | Recetas Nestl칠', 'url': 'https://www.recetasnestle.com.mx/escuela-sabor/recetas-caseras/cocinar-con-pollo', 'content': 'Por esta y otras razones el pollo es uno de los ingredientes preferidos en todos los hogares gracias a sus infinitas posibilidades en la cocina.\\n\\nA continuaci칩n, te mostramos los m칠todos de cocci칩n m치s utilizados en el pollo\\n\\n### **ESTOFADO**\\n\\nUn tipo de cocci칩n prolongada a fuego lento, el pollo queda m치s meloso y conservan todo el sabor de los ingredientes que agregues a la mezcla.\\n\\n### **A LA PARRILLA** [...] Por esta y otras razones el pollo es uno de los ingredientes preferidos en todos los hogares gracias a sus infinitas posibilidades en la cocina.\\n\\nA continuaci칩n, te mostramos los m칠todos de cocci칩n m치s utilizados en el pollo\\n\\n### **ESTOFADO**\\n\\nUn tipo de cocci칩n prolongada a fuego lento, el pollo queda m치s meloso y conservan todo el sabor de los ingredientes que agregues a la mezcla.\\n\\n### **A LA PARRILLA** [...] Por esta y otras razones el pollo es uno de los ingredientes preferidos en todos los hogares gracias a sus infinitas posibilidades en la cocina.\\n\\nA continuaci칩n, te mostramos los m칠todos de cocci칩n m치s utilizados en el pollo\\n\\n### **ESTOFADO**\\n\\nUn tipo de cocci칩n prolongada a fuego lento, el pollo queda m치s meloso y conservan todo el sabor de los ingredientes que agregues a la mezcla.\\n\\n### **A LA PARRILLA**', 'score': 0.70214266}]\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: Para cocinar pollo, existen varios m칠todos populares y deliciosos:\n",
            "\n",
            "1.  **Estofado:** Este m칠todo implica una cocci칩n prolongada a fuego lento, lo que hace que el pollo quede muy tierno y meloso, absorbiendo todos los sabores de los ingredientes a침adidos.\n",
            "2.  **A la parrilla:** Cocinar el pollo a la parrilla le da un sabor ahumado y una textura jugosa por dentro y ligeramente crujiente por fuera.\n",
            "3.  **Rostizado (Asado al horno):** Para un pollo rostizado cl치sico, se precalienta el horno a una temperatura alta (como 400 grados Fahrenheit o 200 grados Celsius). Es importante retirar cualquier paquete de menudencias del interior del pollo y secarlo bien con una toalla de papel antes de sazonar y asar.\n",
            "\n",
            "Adem치s de estos m칠todos, el pollo se puede preparar de muchas otras maneras, como frito, salteado, hervido, o en cazuela, utilizando diferentes condimentos y acompa침amientos.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mPara cocinar pollo, existen varios m칠todos populares y deliciosos:\n",
            "\n",
            "1.  **Estofado:** Este m칠todo implica una cocci칩n prolongada a fuego lento, lo que hace que el pollo quede muy tierno y meloso, absorbiendo todos los sabores de los ingredientes a침adidos.\n",
            "2.  **A la parrilla:** Cocinar el pollo a la parrilla le da un sabor ahumado y una textura jugosa por dentro y ligeramente crujiente por fuera.\n",
            "3.  **Rostizado (Asado al horno):** Para un pollo rostizado cl치sico, se precalienta el horno a una temperatura alta (como 400 grados Fahrenheit o 200 grados Celsius). Es importante retirar cualquier paquete de menudencias del interior del pollo y secarlo bien con una toalla de papel antes de sazonar y asar.\n",
            "\n",
            "Adem치s de estos m칠todos, el pollo se puede preparar de muchas otras maneras, como frito, salteado, hervido, o en cazuela, utilizando diferentes condimentos y acompa침amientos.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: Para cocinar pollo, tienes varias opciones populares:\n",
            "\n",
            "1.  **Estofado:** Cocci칩n lenta que hace que el pollo quede muy tierno y absorba bien los sabores.\n",
            "2.  **A la parrilla:** Le da un sabor ahumado y una textura jugosa por dentro y ligeramente crujiente por fuera.\n",
            "3.  **Rostizado (Asado al horno):** Se precalienta el horno a una temperatura alta (ej. 200춿C o 400춿F). Es importante secar bien el pollo y retirar cualquier paquete de menudencias antes de sazonar y asar.\n",
            "\n",
            "Tambi칠n puedes cocinarlo frito, salteado, hervido o en cazuela, dependiendo de la receta que prefieras.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Para cocinar pollo, tienes varias opciones populares:\n",
            "\n",
            "1.  **Estofado:** Cocci칩n lenta que hace que el pollo quede muy tierno y absorba bien los sabores.\n",
            "2.  **A la parrilla:** Le da un sabor ahumado y una textura jugosa por dentro y ligeramente crujiente por fuera.\n",
            "3.  **Rostizado (Asado al horno):** Se precalienta el horno a una temperatura alta (ej. 200춿C o 400춿F). Es importante secar bien el pollo y retirar cualquier paquete de menudencias antes de sazonar y asar.\n",
            "\n",
            "Tambi칠n puedes cocinarlo frito, salteado, hervido o en cazuela, dependiendo de la receta que prefieras.\n"
          ]
        }
      ],
      "source": [
        "response = supervisor.invoke({\"input\": \"C칩mo puedo cocinar un pollo?\"})\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: search_general_query\n",
            "Action Input: What is Lionel Messi's nationality?\u001b[0m\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: wikipedia\n",
            "Action Input: Lionel Messi\u001b[0m\u001b[33;1m\u001b[1;3mPage: Lionel Messi\n",
            "Summary: Lionel Andr칠s \"Leo\" Messi (Spanish pronunciation: [ljo틛nel an틛d쬰s 틛mesi\u001b[0m\u001b[32;1m\u001b[1;3mThought: The user is asking for Lionel Messi's nationality. I have used the Wikipedia tool and received a snippet of the summary. While the snippet itself does not explicitly state his nationality, it is common knowledge and typically the first piece of information in a Wikipedia summary for a person. I will assume that the full summary from Wikipedia would contain this information, and based on general knowledge, his nationality is Argentinian.\n",
            "Final Answer: Lionel Messi's nationality is Argentinian.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mLionel Messi's nationality is Argentinian.\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: Es argentino.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Es argentino.\n"
          ]
        }
      ],
      "source": [
        "response = supervisor.invoke({\"input\": \"De qu칠 nacionalidad es Lionel Messi?\"})\n",
        "print(response[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las respuestas del enfoque 2.1.4 cambian dado que la pregunta 2 no se responde con la herramienta de RAG, sino que al ser una pregunta m치s general se consulta con la herramienta del agente. Adem치s, ahora que el agente de RAG no responde directamente, el agente supervisor utiliza su respuesta y la entrega en una redacci칩n distinta. Por otro lado, las respuestas del enfoque 2.2.4 utilizan la herramienta del agente, como se esperaba, y entrega respuestas similares a las generadas previamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb8bdAmYvgwn"
      },
      "source": [
        "#### **2.3.4 An치lisis (0.25 puntos)**\n",
        "\n",
        "쯈u칠 diferencias tiene este enfoque con la soluci칩n *Router* vista en clases? Nombre al menos una ventaja y desventaja."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAUlJxqoLK5r"
      },
      "source": [
        "La diferencia es que el agente, en vez de decidir una \"categor칤a\" que despu칠s es parseada para llamar a un segundo agente que resuelve la pregunta, usa a los agentes como herramientas. Una ventaja de esto es que puede llamar a ambos agentes en una sola ejecuci칩n si lo considera pertinente, mientras que una desventaja es que realiza m치s ejecuciones del LLM, porque ahora el supervisor tambi칠n tiene un template tipo ReAct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JWVSuWiZ8Mj"
      },
      "source": [
        "### **2.4 Memoria (Bonus +0.5 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/Gs95aiElrscAAAAd/memory-unlocked-ratatouille-critic.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una de las principales falencias de las soluciones que hemos visto hasta ahora es que nuestro chat no responde las interacciones anteriores, por ejemplo:\n",
        "\n",
        "- Pregunta 1: \"Hola! mi nombre es Sebasti치n\"\n",
        "  - Respuesta esperada: \"Hola Sebasti치n! ...\"\n",
        "- Pregunta 2: \"Cual es mi nombre?\"\n",
        "  - Respuesta actual: \"Lo siento pero no conozco tu nombre :(\"\n",
        "  - **Respuesta esperada: \"Tu nombre es Sebasti치n\"**\n",
        "\n",
        "Para solucionar esto, se les solicita agregar un componente de **memoria** a la soluci칩n entregada en el punto 2.3.\n",
        "\n",
        "**Nota: El Bonus es v치lido <u>s칩lo para la secci칩n 2 de Large Language Models.</u>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "K6Y7tIPJLPfB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/felipe/.pyenv/versions/lab11/lib/python3.11/site-packages/langsmith/client.py:272: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Extendemos el prompt de React para incorporar la interacci칩n previa\n",
        "memory_prompt = hub.pull(\"hwchase17/react\")\n",
        "memory_prompt.template = 'Previous interaction: {memory}\\n' + memory_prompt.template\n",
        "memory_prompt.input_variables.append('memory')\n",
        "\n",
        "memory_agent = create_react_agent(llm, multiagent_tools, memory_prompt) # primero inicializamos el agente ReAct\n",
        "memory_agent_executor = AgentExecutor(agent=memory_agent, tools=multiagent_tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: 춰Hola Felipe! Mucho gusto.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "춰Hola Felipe! Mucho gusto.\n"
          ]
        }
      ],
      "source": [
        "memory = ''\n",
        "\n",
        "def invoke_agent_with_memory(input, memory):\n",
        "    response = memory_agent_executor.invoke({\"input\": input, \"memory\": memory})\n",
        "    memory += f'User: {input}\\n Agent:{response[\"output\"]}'\n",
        "    print(response[\"output\"])\n",
        "    return memory\n",
        "\n",
        "memory = invoke_agent_with_memory(\"Hola, soy Felipe!\", memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: Tu nombre es Felipe.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Tu nombre es Felipe.\n"
          ]
        }
      ],
      "source": [
        "memory = invoke_agent_with_memory(\"Cu치l es mi nombre?\", memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFc3jBT5g0kT"
      },
      "source": [
        "### **2.5 Despliegue (0 puntos)**\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://media1.tenor.com/m/IytHqOp52EsAAAAd/you-get-a-deploy-deploy.gif\"\n",
        "\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "Una vez tengan los puntos anteriores finalizados, toca la etapa de dar a conocer lo que hicimos! Para eso, vamos a desplegar nuestro modelo a trav칠s de `gradio`, una librer칤a especializada en el levantamiento r치pido de demos basadas en ML.\n",
        "\n",
        "Primero instalamos la librer칤a:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "T8TsvnCPbkIA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJBztEUovKsF"
      },
      "source": [
        "Luego s칩lo deben ejecutar el siguiente c칩digo e interactuar con la interfaz a trav칠s del notebook o del link generado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3KedQSvg1-n"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7863\n",
            "* Running on public URL: https://6934e35b6a75d4f859.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://6934e35b6a75d4f859.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: 춰Hola! 쮼n qu칠 puedo ayudarte hoy?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: 춰Hola, Felipe! Es un placer conocerte. 쮿ay algo en lo que pueda ayudarte hoy?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: Te llamas Felipe.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import time\n",
        "\n",
        "def agent_response(message, history):\n",
        "  '''\n",
        "  Funci칩n para gradio, recibe mensaje e historial, devuelte la respuesta del chatbot.\n",
        "  '''\n",
        "  # get chatbot response\n",
        "  response = memory_agent_executor.invoke({\"input\": message, \"memory\": history})[\"output\"] # rellenar con la respuesta de su chat\n",
        "\n",
        "  # assert\n",
        "  assert type(response) == str, \"output de route_question debe ser string\"\n",
        "\n",
        "  # \"streaming\" response\n",
        "  for i in range(len(response)):\n",
        "    time.sleep(0.015)\n",
        "    yield response[: i+1]\n",
        "\n",
        "gr.ChatInterface(\n",
        "    agent_response,\n",
        "    type=\"messages\",\n",
        "    title=\"Chatbot MDS7202\", # Pueden cambiar esto si lo desean\n",
        "    description=\"Hola! Soy un chatbot muy 칰til :)\", # tambi칠n la descripci칩n\n",
        "    theme=\"soft\",\n",
        "    ).launch(\n",
        "        share=True, # pueden compartir el link a sus amig@s para que interactuen con su chat!\n",
        "        debug = False,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80VmXCmnfXnJ"
      },
      "source": [
        "# Conclusi칩n\n",
        "칄xito!\n",
        "<center>\n",
        "<img src =\"https://media.tenor.com/MRQgxcelAV8AAAAM/perry-the-platypus-phineas-and-ferb.gif\" width = 400 />"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "lab11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0678c1f060f54ad289eeb8cc079a4739": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a115967f34d4dcebbf328cc16ecb845": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0678c1f060f54ad289eeb8cc079a4739",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較</span> <span style=\"color: #008000; text-decoration-color: #008000\">10,178/10,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:21</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">469 it/s</span> ]\n</pre>\n",
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\u001b[0m \u001b[32m10,178/10,000 \u001b[0m [ \u001b[33m0:00:21\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m469 it/s\u001b[0m ]\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "be65422cf0be4c90bab935bc012c609d": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_cabdbad743c54b05bdbe6e0606611f8f",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較</span> <span style=\"color: #008000; text-decoration-color: #008000\">100,341/100,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:06:32</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">261 it/s</span> ]\n</pre>\n",
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較\u001b[0m \u001b[32m100,341/100,000 \u001b[0m [ \u001b[33m0:06:32\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m261 it/s\u001b[0m ]\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "cabdbad743c54b05bdbe6e0606611f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
